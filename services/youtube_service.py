import time
import os
import requests
import datetime
import tiktoken
from cachetools import TTLCache
from math import ceil
from langdetect import detect
from dotenv import load_dotenv
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound
from bs4 import BeautifulSoup
import openai
from googleapiclient.discovery import build
import googlemaps
from typing import List, Dict, Tuple, Any
from models.youtube_schemas import YouTubeResponse, VideoInfo, PlaceInfo, PlacePhoto, ContentType, ContentInfo, PlaceGeometry
from repository.youtube_repository import YouTubeRepository
from langchain.schema import Document
from urllib.parse import urlparse, parse_qs
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from fastapi import APIRouter, HTTPException, status
import asyncio
import aiohttp
from asyncio import Semaphore
import httpx

from ai_api.youtube_subtitle import (
    get_video_info, process_link, split_text, summarize_text,
    extract_place_names, search_place_details, get_place_photo_google
)

# í™˜ê²½ ë³€ìˆ˜ ë° ìƒìˆ˜ ì„¤ì •
load_dotenv(dotenv_path=".env")

# API í‚¤ ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")
GEOCODING_API_KEY = os.getenv("GOOGLE_GEOCODING_API_KEY")
GOOGLE_PLACES_API_KEY = os.getenv("GOOGLE_PLACES_API_KEY")

# ìƒìˆ˜ ì„¤ì •
MAX_URLS = 5
CHUNK_SIZE = 2048
MODEL = "gpt-4o-mini"
FINAL_SUMMARY_MAX_TOKENS = 1500

class ContentService:
    """ì»¨í…ì¸  ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def get_content_info(url: str) -> Tuple[str, str, ContentType]:
        """URLì—ì„œ ì»¨í…ì¸  ì •ë³´ ì¶”ì¶œ"""
        content_type = ContentService._detect_content_type(url)
        
        if content_type == ContentType.YOUTUBE:
            title, author = YouTubeSubtitleService.get_video_info(url)
        elif content_type == ContentType.NAVER_BLOG:
            title, author = ContentService._get_naver_blog_info(url)
        elif content_type == ContentType.TISTORY:
            title, author = ContentService._get_tistory_blog_info(url)
        else:
            title, author = ContentService._get_webpage_info(url)
            
        return title, author, content_type

    @staticmethod
    def _detect_content_type(url: str) -> ContentType:
        """URL ìœ í˜• ê°ì§€"""
        domain = urlparse(url).netloc.lower()
        
        if "youtube.com" in domain or "youtu.be" in domain:
            return ContentType.YOUTUBE
        elif "blog.naver.com" in domain:
            return ContentType.NAVER_BLOG
        elif ".tistory.com" in domain:
            return ContentType.TISTORY
        elif url.endswith(".txt"):
            return ContentType.TEXT_FILE
        elif url.startswith("http"):
            return ContentType.WEBPAGE
        return ContentType.UNKNOWN

    @staticmethod
    def _get_naver_blog_info(url: str) -> Tuple[str, str]:
        """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # iframe ë‚´ë¶€ì˜ ì‹¤ì œ ì»¨í…ì¸  URL ì°¾ê¸°
            if 'blog.naver.com' in url:
                iframe = soup.find('iframe', id='mainFrame')
                if iframe and iframe.get('src'):
                    real_url = f"https://blog.naver.com{iframe['src']}"
                    response = requests.get(real_url, headers=headers)
                    soup = BeautifulSoup(response.text, 'html.parser')
            
            title = soup.find('meta', property='og:title')
            title = title['content'] if title else "ì œëª© ì—†ìŒ"
            
            author = soup.find('meta', property='og:article:author')
            author = author['content'] if author else "ì‘ì„±ì ì—†ìŒ"
            
            return title, author
        except Exception as e:
            print(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None, None

    @staticmethod
    def _get_tistory_blog_info(url: str) -> Tuple[str, str]:
        """í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            title = soup.find('meta', property='og:title')
            title = title['content'] if title else "ì œëª© ì—†ìŒ"
            
            author = soup.find('meta', property='og:article:author')
            author = author['content'] if author else "ì‘ì„±ì ì—†ìŒ"
            
            return title, author
        except Exception as e:
            print(f"í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None, None

    @staticmethod
    def process_content(url: str) -> str:
        """URLì—ì„œ ì»¨í…ì¸  ì¶”ì¶œ"""
        content_type = ContentService._detect_content_type(url)
        
        if content_type == ContentType.YOUTUBE:
            return YouTubeSubtitleService.process_link(url)
        elif content_type == ContentType.NAVER_BLOG:
            return ContentService._get_naver_blog_content(url)
        elif content_type == ContentType.TISTORY:
            return ContentService._get_tistory_blog_content(url)
        elif content_type == ContentType.TEXT_FILE:
            return YouTubeSubtitleService._get_text_from_file(url)
        else:
            return YouTubeSubtitleService._get_text_from_webpage(url)

    @staticmethod
    def _get_naver_blog_content(url: str) -> str:
        """ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ë¶ˆí•„ìš”í•œ ê°œí–‰ ë° ê³µë°±, ê´‘ê³  ì œê±° í¬í•¨)"""
        cache = TTLCache(maxsize=10, ttl=300)

        if url in cache:
            return cache[url]

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }

        def clean_text(text: str) -> str:
            import re
            text = re.sub(r'\s+', ' ', text)  # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
            text = re.sub(r'[^\S\r\n]+', ' ', text)  # ìœ ë‹ˆì½”ë“œ ê³µë°± ì œê±°
            text = re.sub(r'Â©.*?(?= )', '', text)   # Â© ë“± ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ ì œê±°
            text = re.sub(r'\[ë°”ë¡œê°€ê¸°\]', '', text)
            return text.strip()

        try:
            # ì²« ë²ˆì§¸ ìš”ì²­ìœ¼ë¡œ iframe URL ê°€ì ¸ì˜¤ê¸°
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')

            # iframe ì°¾ê¸° (ìƒˆ ë²„ì „ ë¸”ë¡œê·¸)
            iframe = soup.find('iframe', id='mainFrame')
            if iframe and iframe.get('src'):
                real_url = f"https://blog.naver.com{iframe['src']}"
                response = requests.get(real_url, headers=headers)
                response.raise_for_status()
                soup = BeautifulSoup(response.text, 'html.parser')

            # ìƒˆë¡œìš´ ë²„ì „ ë¸”ë¡œê·¸ ì˜ì—­
            content = soup.find('div', {'class': 'se-main-container'})
            if not content:
                # êµ¬ë²„ì „ ë¸”ë¡œê·¸ ì˜ì—­
                content = soup.find('div', {'class': 'post-view'})
            if not content:
                raise HTTPException(status_code=404, detail="ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
            for tag in content.find_all(['script', 'style']):
                tag.decompose()

            text = clean_text(content.get_text(separator='\n'))
            cache[url] = text
            return text

        except requests.RequestException as e:
            raise HTTPException(status_code=500, detail=f"ë¸”ë¡œê·¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    @staticmethod
    def _get_tistory_blog_content(url: str) -> str:
        """í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ì»¨í…ì¸  ì¶”ì¶œ"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ë³¸ë¬¸ ì»¨í…ì¸  ì°¾ê¸°
            content = soup.find('div', {'class': 'entry-content'})
            if not content:
                content = soup.find('div', {'class': 'article'})
            
            if content:
                # ë¶ˆí•„ìš”í•œ ìš”ì†Œ ì œê±°
                for element in content.find_all(['script', 'style']):
                    element.decompose()
                
                text = content.get_text(separator='\n').strip()
                return text
            
            return "ì»¨í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        except Exception as e:
            print(f"í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ ì»¨í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return "ì»¨í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨"

class YouTubeService:
    """ë©”ì¸ YouTube ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        """YouTubeService ì´ˆê¸°í™”"""
        from dotenv import load_dotenv
        load_dotenv()  # .env íŒŒì¼ ë¡œë“œ
        
        self.repository = YouTubeRepository()
        self.content_service = ContentService()
        self.text_service = TextProcessingService()
        self.place_service = PlaceService()
        
        # Google Maps API í‚¤ í™•ì¸ ë° ì„¤ì •
        google_maps_api_key = os.getenv('GOOGLE_PLACES_API_KEY')  # GOOGLE_MAPS_API_KEY ëŒ€ì‹  GOOGLE_PLACES_API_KEY ì‚¬ìš©
        if not google_maps_api_key:
            raise ValueError("GOOGLE_PLACES_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            self.gmaps = googlemaps.Client(key=google_maps_api_key)
        except Exception as e:
            raise ValueError(f"Google Maps í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")

        # ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´ ì¶”ê°€
        self.semaphore = Semaphore(10)  # ìµœëŒ€ 10ê°œì˜ ë™ì‹œ ìš”ì²­ í—ˆìš©
        self.session = None

    async def get_session(self) -> aiohttp.ClientSession:
        """ë¹„ë™ê¸° HTTP ì„¸ì…˜ ë°˜í™˜"""
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession()
        return self.session

    async def process_urls(self, urls: List[str]) -> Dict:
        try:
            content_infos = []
            place_details = []
            start_time = time.time()
            
            # ë¹„ë™ê¸° ì‘ì—… ëª©ë¡ ìƒì„±
            tasks = []
            async with aiohttp.ClientSession() as session:
                for url in urls:
                    task = self.process_single_url(url, session)
                    tasks.append(task)
                
                # ëª¨ë“  ì‘ì—… ë™ì‹œ ì‹¤í–‰
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # ê²°ê³¼ ì²˜ë¦¬
                for result in results:
                    if isinstance(result, Exception):
                        print(f"URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(result)}")
                        continue
                    
                    if result:
                        content_info, places = result
                        content_infos.append(content_info)
                        place_details.extend(places)

            processing_time = time.time() - start_time

            # ìµœì¢… ìš”ì•½ ìƒì„±
            summaries = {}
            for content in content_infos:
                places = [p for p in place_details if p.source_url == content.url]
                summary = self._format_final_result(
                    content_infos=[content],
                    place_details=places,
                    processing_time=processing_time,
                    urls=[content.url]
                )
                summaries[content.url] = summary

            # ë²¡í„° DBì™€ íŒŒì¼ì— ë¹„ë™ê¸° ì €ì¥
            await self.repository.save_to_vectordb(summaries, content_infos, place_details)
            await self.repository.save_final_summary(summaries, content_infos)

            return {
                "summary": summaries,
                "content_infos": [info.dict() for info in content_infos],
                "processing_time_seconds": processing_time,
                "place_details": [place.dict() for place in place_details]
            }

        except Exception as e:
            raise ValueError(f"URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    async def process_single_url(self, url: str, session: aiohttp.ClientSession) -> Tuple[ContentInfo, List[PlaceInfo]]:
        """ë‹¨ì¼ URL ë¹„ë™ê¸° ì²˜ë¦¬"""
        async with self.semaphore:  # ë™ì‹œì„± ì œì–´
            try:
                parsed_url = urlparse(url)
                if 'youtube.com' in parsed_url.netloc:
                    return await self._process_youtube_url(url, session)
                elif 'blog.naver.com' in parsed_url.netloc:
                    return await self._process_naver_blog_url(url, session)
                # ë‹¤ë¥¸ URL íƒ€ì… ì²˜ë¦¬...
            except Exception as e:
                print(f"URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                raise

    async def _process_youtube_url(self, url: str, session: aiohttp.ClientSession) -> Tuple[ContentInfo, List[PlaceInfo]]:
        """YouTube URL ë¹„ë™ê¸° ì²˜ë¦¬"""
        video_id = parse_qs(urlparse(url).query).get('v', [None])[0]
        if not video_id:
            raise ValueError("ì˜ëª»ëœ YouTube URL")

        # ë¹„ë””ì˜¤ ì •ë³´ ë¹„ë™ê¸° ìš”ì²­
        video_info = await self._get_video_info_async(video_id, session)
        content_info = ContentInfo(
            url=url,
            title=video_info.title,
            author=video_info.channel,
            platform=ContentType.YOUTUBE
        )

        # ìë§‰ ë° ì¥ì†Œ ì •ë³´ ë¹„ë™ê¸° ì²˜ë¦¬
        transcript = await self._get_youtube_transcript_async(video_id)
        places = await self._process_youtube_video_async(video_id, url, transcript)

        return content_info, places

    async def _get_video_info_async(self, video_id: str, session: aiohttp.ClientSession) -> VideoInfo:
        """ë¹„ë””ì˜¤ ì •ë³´ ë¹„ë™ê¸° ìš”ì²­"""
        api_url = f"https://noembed.com/embed?url=https://www.youtube.com/watch?v={video_id}"
        try:
            async with session.get(api_url) as response:
                # ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ê°€ì ¸ì˜´
                text = await response.text()
                try:
                    # í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ íŒŒì‹±
                    import json
                    data = json.loads(text)
                    return VideoInfo(
                        url=f"https://www.youtube.com/watch?v={video_id}",
                        title=data.get('title'),
                        channel=data.get('author_name')
                    )
                except json.JSONDecodeError:
                    print(f"JSON íŒŒì‹± ì‹¤íŒ¨: {text[:200]}")  # ì²˜ìŒ 200ìë§Œ ë¡œê·¸ë¡œ ì¶œë ¥
                
        except Exception as e:
            print(f"ë¹„ë””ì˜¤ ì •ë³´ ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
        
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return VideoInfo(
            url=f"https://www.youtube.com/watch?v={video_id}",
            title="ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ",
            channel="ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
        )

    async def _get_youtube_transcript_async(self, video_id: str) -> str:
        """YouTube ìë§‰ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ê°€ì ¸ì˜´"""
        try:
            # YouTubeTranscriptApiëŠ” ë¹„ë™ê¸°ë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ThreadPoolì—ì„œ ì‹¤í–‰
            loop = asyncio.get_event_loop()
            transcript_text = await loop.run_in_executor(None, self._get_youtube_transcript, video_id)
            return transcript_text
        except Exception as e:
            print(f"ìë§‰ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return ""

    async def _process_youtube_video_async(self, video_id: str, source_url: str, transcript_text: str) -> List[PlaceInfo]:
        """YouTube ì˜ìƒì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì¥ì†Œ ì •ë³´ë¥¼ ìˆ˜ì§‘"""
        try:
            # í…ìŠ¤íŠ¸ ë¶„í•  ë° ìš”ì•½
            chunks = self.text_service.split_text(transcript_text)
            summary = self.text_service.summarize_text(chunks)
            
            # ì¥ì†Œ ì¶”ì¶œ ë° ì •ë³´ ìˆ˜ì§‘
            place_names = self.place_service.extract_place_names(summary)
            print(f"ì¶”ì¶œëœ ì¥ì†Œ: {place_names}")
            
            # ì¥ì†Œ ì •ë³´ ìˆ˜ì§‘
            place_details = []
            for place_name in place_names:
                try:
                    # Google Places API í˜¸ì¶œì€ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
                    loop = asyncio.get_event_loop()
                    places_result = await loop.run_in_executor(
                        None, self.gmaps.places, place_name
                    )
                    
                    if places_result['results']:
                        place = places_result['results'][0]
                        place_id = place['place_id']
                        
                        # ì¥ì†Œ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        details = await loop.run_in_executor(
                            None, 
                            lambda: self.gmaps.place(place_id, language='ko')['result']
                        )
                        
                        # ì¥ì†Œ íƒ€ì…ê³¼ ì¢Œí‘œ ì •ë³´ ì¶”ì¶œ
                        place_type = details.get('types', ['unknown'])[0]
                        location = details.get('geometry', {}).get('location', {})
                        geometry = PlaceGeometry(
                            latitude=location.get('lat'),
                            longitude=location.get('lng')
                        )
                        
                        place_info = PlaceInfo(
                            name=place_name,
                            source_url=source_url,
                            type=place_type,
                            geometry=geometry,
                            description=self._extract_place_description(summary, place_name),
                            official_description=await loop.run_in_executor(
                                None,
                                self._get_place_description_from_openai,
                                place_name,
                                place_type
                            ),
                            formatted_address=details.get('formatted_address'),
                            rating=details.get('rating'),
                            phone=details.get('formatted_phone_number'),
                            website=details.get('website'),
                            price_level=details.get('price_level'),
                            opening_hours=details.get('opening_hours', {}).get('weekday_text'),
                            google_info=details
                        )
                        
                        # ì‚¬ì§„ URL ì¶”ê°€
                        if 'photos' in details:
                            photo_ref = details['photos'][0]['photo_reference']
                            photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_ref}&key={os.getenv('GOOGLE_PLACES_API_KEY')}"
                            place_info.photos = [PlacePhoto(url=photo_url)]
                        
                        place_details.append(place_info)
                        
                except Exception as e:
                    print(f"ì¥ì†Œ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({place_name}): {str(e)}")
                    continue
            
            return place_details
            
        except Exception as e:
            print(f"YouTube ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return []

    def _process_youtube_video(self, video_id: str, source_url: str) -> List[PlaceInfo]:
        """YouTube ì˜ìƒì„ ì²˜ë¦¬í•˜ì—¬ ì¥ì†Œ ì •ë³´ë¥¼ ìˆ˜ì§‘"""
        try:
            # YouTube ìë§‰ ê°€ì ¸ì˜¤ê¸°
            transcript_text = self._get_youtube_transcript(video_id)
            
            # í…ìŠ¤íŠ¸ ë¶„í•  ë° ìš”ì•½
            chunks = self.text_service.split_text(transcript_text)
            summary = self.text_service.summarize_text(chunks)
            
            # ì¥ì†Œ ì¶”ì¶œ ë° ì •ë³´ ìˆ˜ì§‘
            place_names = self.place_service.extract_place_names(summary)
            print(f"ì¶”ì¶œëœ ì¥ì†Œ: {place_names}")
            
            # ì¥ì†Œ ì •ë³´ ìˆ˜ì§‘
            place_details = []
            for place_name in place_names:
                try:
                    # Google Places APIë¡œ ì¥ì†Œ ì •ë³´ ê²€ìƒ‰
                    places_result = self.gmaps.places(place_name)
                    if places_result['results']:
                        place = places_result['results'][0]
                        place_id = place['place_id']
                        details = self.gmaps.place(place_id, language='ko')['result']
                        
                        # ì¥ì†Œ íƒ€ì…ê³¼ ì¢Œí‘œ ì •ë³´ ì¶”ì¶œ
                        place_type = details.get('types', ['unknown'])[0]
                        location = details.get('geometry', {}).get('location', {})
                        geometry = PlaceGeometry(
                            latitude=location.get('lat'),
                            longitude=location.get('lng')
                        )
                        
                        place_info = PlaceInfo(
                            name=place_name,
                            source_url=source_url,
                            type=place_type,  # ì¥ì†Œ íƒ€ì… ì„¤ì •
                            geometry=geometry,  # geometry ì •ë³´ ì„¤ì •
                            description=self._extract_place_description(summary, place_name),
                            official_description=self._get_place_description_from_openai(place_name, place_type),  # official_description ì„¤ì •
                            formatted_address=details.get('formatted_address'),
                            rating=details.get('rating'),
                            phone=details.get('formatted_phone_number'),
                            website=details.get('website'),
                            price_level=details.get('price_level'),
                            opening_hours=details.get('opening_hours', {}).get('weekday_text'),
                            google_info=details
                        )
                        
                        # ì‚¬ì§„ URL ì¶”ê°€
                        if 'photos' in details:
                            photo_ref = details['photos'][0]['photo_reference']
                            photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_ref}&key={os.getenv('GOOGLE_PLACES_API_KEY')}"
                            place_info.photos = [PlacePhoto(url=photo_url)]
                        
                        # ë² ìŠ¤íŠ¸ ë¦¬ë·° ì¶”ê°€
                        if 'reviews' in details:
                            best_review = max(details['reviews'], key=lambda x: x.get('rating', 0))
                            place_info.best_review = best_review.get('text')
                    
                    place_details.append(place_info)
                    print(f"ì¥ì†Œ ì •ë³´ ì¶”ê°€ ì™„ë£Œ: {place_name}")
                    
                except Exception as e:
                    print(f"ì¥ì†Œ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({place_name}): {str(e)}")
                    # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì¶”ê°€
                    place_details.append(PlaceInfo(
                        name=place_name,
                        source_url=source_url,  # source_url ì¶”ê°€
                        description=self._extract_place_description(summary, place_name),
                        google_info={}
                    ))
                    continue
            
            return place_details
            
        except Exception as e:
            raise Exception(f"URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def _process_naver_blog(self, url: str) -> List[PlaceInfo]:
        """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ì„ ì²˜ë¦¬í•˜ì—¬ ìš”ì•½ì„ ìƒì„±"""
        try:
            import requests
            from bs4 import BeautifulSoup
            
            # ë¸”ë¡œê·¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            response = requests.get(url)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ
            content = soup.get_text()
            
            # í…ìŠ¤íŠ¸ ë¶„í•  ë° ìš”ì•½
            chunks = self.text_service.split_text(content)
            summary = self.text_service.summarize_text(chunks)
            
            # ì¥ì†Œ ì¶”ì¶œ ë° ì •ë³´ ìˆ˜ì§‘
            place_names = self.place_service.extract_place_names(summary)
            print(f"ì¶”ì¶œëœ ì¥ì†Œ: {place_names}")
            
            # ì¥ì†Œ ì •ë³´ ìˆ˜ì§‘
            place_details = []
            for place_name in place_names:
                try:
                    # Google Places APIë¡œ ì¥ì†Œ ì •ë³´ ê²€ìƒ‰
                    place_info = PlaceInfo(
                        name=place_name,
                        source_url=url,
                        description=self._extract_place_description(summary, place_name),
                        google_info={}
                    )
                    
                    # Google Places API ê²€ìƒ‰ ì‹œë„
                    places_result = self.gmaps.places(place_name)
                    if places_result['results']:
                        place = places_result['results'][0]
                        place_id = place['place_id']
                        details = self.gmaps.place(place_id, language='ko')['result']
                        
                        # OpenAIë¡œ ì¥ì†Œ ì„¤ëª… ìƒì„±
                        official_description = self._get_place_description_from_openai(place_name, details.get('types', ['ì •ë³´ ì—†ìŒ'])[0])
                        if official_description:
                            place_info.official_description = official_description
                        
                        # ì¶”ê°€ ì •ë³´ ì—…ë°ì´íŠ¸
                        place_info.formatted_address = details.get('formatted_address')
                        place_info.rating = details.get('rating')
                        place_info.phone = details.get('formatted_phone_number')
                        place_info.website = details.get('website')
                        place_info.price_level = details.get('price_level')
                        place_info.opening_hours = details.get('opening_hours', {}).get('weekday_text')
                        place_info.google_info = details
                        
                        # ì‚¬ì§„ URL ì¶”ê°€
                        if 'photos' in details:
                            photo_ref = details['photos'][0]['photo_reference']
                            photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_ref}&key={os.getenv('GOOGLE_PLACES_API_KEY')}"
                            place_info.photos = [PlacePhoto(url=photo_url)]
                        
                        # ë² ìŠ¤íŠ¸ ë¦¬ë·° ì¶”ê°€
                        if 'reviews' in details:
                            best_review = max(details['reviews'], key=lambda x: x.get('rating', 0))
                            place_info.best_review = best_review.get('text')
                    
                    place_details.append(place_info)
                    print(f"ì¥ì†Œ ì •ë³´ ì¶”ê°€ ì™„ë£Œ: {place_name}")
                    
                except Exception as e:
                    print(f"ì¥ì†Œ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({place_name}): {str(e)}")
                    # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê¸°ë³¸ ì •ë³´ëŠ” ì¶”ê°€
                    place_details.append(PlaceInfo(
                        name=place_name,
                        source_url=url,
                        description=self._extract_place_description(summary, place_name),
                        google_info={}
                    ))
                    continue
            
            return place_details
            
        except Exception as e:
            raise Exception(f"URL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def _extract_place_description(self, summary: str, place_name: str) -> str:
        """ìš”ì•½ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ì¥ì†Œì— ëŒ€í•œ ì„¤ëª…ì„ ì¶”ì¶œ"""
        try:
            lines = summary.split('\n')
            description = ""
            
            for i, line in enumerate(lines):
                if place_name in line:
                    # í˜„ì¬ ì¤„ê³¼ ë‹¤ìŒ ëª‡ ì¤„ì„ í¬í•¨í•˜ì—¬ ì„¤ëª… ì¶”ì¶œ
                    description = ' '.join(lines[i:i+3])
                    break
            
            return description.strip() or "ì¥ì†Œ ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            print(f"ì¥ì†Œ ì„¤ëª… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return "ì¥ì†Œ ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def _format_final_result(self, content_infos: List[ContentInfo], place_details: List[PlaceInfo], processing_time: float, urls: List[str]) -> str:
        """ìµœì¢… ê²°ê³¼ ë¬¸ìì—´ì„ í¬ë§·íŒ…í•˜ëŠ” ë©”ì„œë“œ"""
        
        # 1. ê¸°ë³¸ ì •ë³´ í—¤ë”
        final_result = f"""
=== ì—¬í–‰ ì •ë³´ ìš”ì•½ ===
ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ

ë¶„ì„í•œ ì˜ìƒ:
{'='*50}"""
        
        # 2. ë¹„ë””ì˜¤ ì •ë³´
        if content_infos:
            for info in content_infos:
                final_result += f"""
ì œëª©: {info.title}
ì±„ë„: {info.author}
URL: {info.url}"""
        else:
            final_result += f"\nURL: {chr(10).join(urls)}"
        
        final_result += f"\n{'='*50}\n\n=== ì¥ì†Œë³„ ìƒì„¸ ì •ë³´ ===\n"

        # 3. ì¥ì†Œë³„ ì •ë³´
        for idx, place in enumerate(place_details, 1):
            final_result += f"""
{idx}. {place.name}
{'='*50}

[ìœ íŠœë²„ì˜ ë¦¬ë·°]"""
            
            # ì„¤ëª…ì—ì„œ "ë°©ë¬¸í•œ ì¥ì†Œ:" ë¶€ë¶„ ì œê±°
            description = place.description or 'ì¥ì†Œ ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            if "ë°©ë¬¸í•œ ì¥ì†Œ:" in description:
                # "ë°©ë¬¸í•œ ì¥ì†Œ:" ì´í›„ì˜ ì²« ë²ˆì§¸ "-" ë˜ëŠ” "íƒ€ì„ìŠ¤íƒ¬í”„:" ì´ì „ê¹Œì§€ì˜ í…ìŠ¤íŠ¸ ì œê±°
                parts = description.split(" - ", 1)
                if len(parts) > 1:
                    description = parts[1].strip()
            
            # ì„¤ëª…ê³¼ ì¶”ì²œì‚¬í•­ ë¶„ë¦¬
            if " - ì¶”ì²œ ì‚¬í•­:" in description:
                desc_parts = description.split(" - ì¶”ì²œ ì‚¬í•­:", 1)
                description = desc_parts[0].strip()
                recommendations = desc_parts[1].strip()
                final_result += f"""
ì¥ì†Œì„¤ëª…: {description}

[ì¶”ì²œ ì‚¬í•­]
{recommendations}"""
            else:
                final_result += f"""
ì¥ì†Œì„¤ëª…: {description}"""

            # êµ¬ê¸€ ì¥ì†Œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
            if place.google_info:
                
                final_result += f"""

                [ì¥ì†Œ ì„¤ëª…]
{place.official_description or 'ì„¤ëª… ì—†ìŒ'}
[êµ¬ê¸€ ì¥ì†Œ ì •ë³´]
ì¥ì†Œíƒ€ì…: {place.types[0] if place.types and len(place.types) > 0 else 'ì •ë³´ ì—†ìŒ'}
ğŸ  ì£¼ì†Œ: {place.formatted_address or 'ì •ë³´ ì—†ìŒ'}
â­ í‰ì : {place.rating or 'None'}
ğŸ“ ì „í™”: {place.phone or 'None'}
ğŸŒ ì›¹ì‚¬ì´íŠ¸: {place.website or 'None'}
ğŸ’° ê°€ê²©ëŒ€: {'â‚©' * place.price_level if place.price_level else 'ì •ë³´ ì—†ìŒ'}
â° ì˜ì—…ì‹œê°„:
{chr(10).join(place.opening_hours if place.opening_hours else ['ì •ë³´ ì—†ìŒ'])}

[ì‚¬ì§„ ë° ë¦¬ë·°]"""
                
                if place.photos:
                    for photo_idx, photo in enumerate(place.photos, 1):
                        final_result += f"""
ğŸ“¸ ì‚¬ì§„ {photo_idx}: {photo.url}"""
                
                final_result += f"""
â­ ë² ìŠ¤íŠ¸ ë¦¬ë·°: {place.best_review or 'ë¦¬ë·° ì—†ìŒ'}"""
            
            final_result += f"\n{'='*50}"
        
        return final_result

    def search_content(self, query: str) -> List[Dict]:
        """ë²¡í„° DBì—ì„œ ì½˜í…ì¸  ê²€ìƒ‰"""
        try:
            results = self.repository.query_vectordb(query)
            filtered_results = []

            for doc in results:
                if isinstance(doc, Document) and hasattr(doc, "metadata") and hasattr(doc, "page_content"):
                    filtered_results.append({
                        'content': doc.page_content,
                        'metadata': doc.metadata
                    })
                else:
                    print(f"âš ï¸ ì˜ëª»ëœ ë°ì´í„° íƒ€ì… ê°ì§€: {type(doc)} - {doc}")

            return filtered_results
        except Exception as e:
            raise Exception(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    @staticmethod
    def _get_youtube_transcript(video_id: str) -> str:
        """YouTube ì˜ìƒì˜ ìë§‰ì„ ê°€ì ¸ì˜´"""
        try:
            transcripts = YouTubeTranscriptApi.list_transcripts(video_id)
            
            # 1. ë¨¼ì € í•œêµ­ì–´ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_transcript(['ko'])
                transcript_text = "\n".join([f"[{YouTubeService._format_timestamp(entry['start'])}] {entry['text']}" 
                                           for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] í•œêµ­ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except (TranscriptsDisabled, NoTranscriptFound):
                print("[get_youtube_transcript] í•œêµ­ì–´ ìë§‰ ì—†ìŒ.")

            # 2. ì˜ì–´ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_transcript(['en'])
                transcript_text = "\n".join([f"[{YouTubeService._format_timestamp(entry['start'])}] {entry['text']}" 
                                           for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] ì˜ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except (TranscriptsDisabled, NoTranscriptFound):
                print("[get_youtube_transcript] ì˜ì–´ ìë§‰ ì—†ìŒ.")

            # 3. ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_generated_transcript()
                transcript_text = "\n".join([f"[{YouTubeService._format_timestamp(entry['start'])}] {entry['text']}" 
                                           for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] ìƒì„±ëœ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except Exception as e:
                print(f"[get_youtube_transcript] ìƒì„±ëœ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            raise ValueError(f"ë¹„ë””ì˜¤ {video_id}ì˜ ìë§‰ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

    @staticmethod
    def _format_timestamp(seconds: float) -> str:
        """ì´ˆë¥¼ ì‹œ:ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"

    def _get_video_info(self, video_id: str) -> VideoInfo:
        """YouTube ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜´"""
        try:
            import requests
            
            # noembed APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            api_url = f"https://noembed.com/embed?url=https://www.youtube.com/watch?v={video_id}"
            response = requests.get(api_url)
            
            if response.status_code == 200:
                data = response.json()
                return VideoInfo(
                    url=f"https://www.youtube.com/watch?v={video_id}",
                    title=data.get('title'),
                    channel=data.get('author_name')
                )
            else:
                print(f"[get_video_info] API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
                return VideoInfo(
                    url=f"https://www.youtube.com/watch?v={video_id}",
                    title="ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ",
                    channel="ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
                )
            
        except Exception as e:
            print(f"ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            return VideoInfo(
                url=f"https://www.youtube.com/watch?v={video_id}",
                title="ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ",
                channel="ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
            )

    def _get_blog_info(self, url: str) -> Dict[str, str]:
        """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜´"""
        try:
            import requests
            from bs4 import BeautifulSoup
            
            response = requests.get(url)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ë¸”ë¡œê·¸ ì œëª© ì¶”ì¶œ ì‹œë„
            title = None
            title_tag = soup.find('meta', property='og:title')
            if title_tag:
                title = title_tag.get('content')
            
            if not title:
                title_tag = soup.find('title')
                if title_tag:
                    title = title_tag.text
            
            # ì‘ì„±ì ì •ë³´ ì¶”ì¶œ ì‹œë„
            author = None
            author_tag = soup.find('meta', property='og:article:author')
            if author_tag:
                author = author_tag.get('content')
            
            if not author:
                # ë¸”ë¡œê·¸ URLì—ì„œ ì‘ì„±ì ID ì¶”ì¶œ
                try:
                    blog_id = url.split('blog.naver.com/')[1].split('/')[0]
                    author = f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ | {blog_id}"
                except:
                    author = "ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì‘ì„±ì"
            
            return {
                'title': title or "ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ",
                'author': author or "ì‘ì„±ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
            }
            
        except Exception as e:
            print(f"ë¸”ë¡œê·¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            return {
                'title': "ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ",
                'author': "ì‘ì„±ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
            }

    def generate_final_summary(self, content_infos: List[ContentInfo], processing_time: float, place_details: List[PlaceInfo]) -> Dict[str, str]:
        """ìµœì¢… ìš”ì•½ì„ ìƒì„±
        ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¥ì†Œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.

1. ì¥ì†Œê°€ í•œêµ­ì´ ì•„ë‹ˆë¼ ì¼ë³¸ì˜ ì–´ëŠ ì§€ì—­ì— ìœ„ì¹˜í•œ ê²½ìš°ì—ë§Œ ì •ë³´ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”.
2. ìƒí˜¸ëª…ì´ ì—†ëŠ” ê²½ìš°, ìœ íŠœë²„ê°€ ë§í•œ ì§€ì—­(ì˜ˆ: 'ë„ì¿„') ë‚´ì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬(ì˜ˆ: ìŒì‹ì , ê´€ê´‘ì§€)ì— ë§ëŠ” ìœ ëª…í•œ ê³³ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
3. 'ë„ì¿„'ì²˜ëŸ¼ í° ì§€ì—­ì´ ì–¸ê¸‰ë˜ì—ˆì„ ê²½ìš°, ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ì¥ì†Œ(ì˜ˆ: 'ì˜¤ë‹¤ì´ë°” ê±°ë¦¬', 'ì‹ ì£¼ì¿  ê³¨ë“ ê°€ì´')ë¡œ ì„¸ë¶„í™”í•˜ì—¬ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
4. ìœ„ë„ ë° ê²½ë„ê°€ ì—†ëŠ” ì´ë¯¸ì§€ëŠ” ì œì™¸í•˜ê±°ë‚˜, í•´ë‹¹ ì¥ì†Œì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”.
5. ì¤‘ë³µëœ ì¥ì†ŒëŠ” ì œê±°í•˜ê³ , ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ì •ë³´ë§Œ ì œê³µí•©ë‹ˆë‹¤."""
        summaries = {}
        
        for content in content_infos:
            summary = f"=== ì—¬í–‰ ì •ë³´ ìš”ì•½ ===\n"
            summary += f"ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ\n\n"
            
            # ë¶„ì„í•œ ì½˜í…ì¸  ì •ë³´
            summary += "ë¶„ì„í•œ ì½˜í…ì¸ :\n"
            summary += "=" * 50 + "\n"
            for idx, info in enumerate(content_infos, 1):
                summary += f"{idx}. {info.platform.value.upper()}\n"
                summary += f"ì œëª©: {info.title}\n"
                summary += f"ì‘ì„±ì: {info.author}\n"
                summary += f"URL: {info.url}\n\n"
            
            summary += "=" * 50 + "\n\n"
            
            # ì¥ì†Œë³„ ìƒì„¸ ì •ë³´
            summary += "=== ì¥ì†Œë³„ ìƒì„¸ ì •ë³´ ===\n\n"
            
            # í˜„ì¬ ì½˜í…ì¸ ì™€ ê´€ë ¨ëœ ì¥ì†Œë§Œ í•„í„°ë§
            content_places = [place for place in place_details if place.source_url == content.url]
            
            for idx, place in enumerate(content_places, 1):
                summary += f"{idx}. {place.name}\n"
                summary += "=" * 50 + "\n\n"
                
                # ìœ íŠœë²„/ë¸”ë¡œê±°ì˜ ë¦¬ë·°
                summary += "[ìœ íŠœë²„/ë¸”ë¡œê±°ì˜ ë¦¬ë·°]\n"
                summary += f"ì¥ì†Œì„¤ëª…: {place.description or 'ì¥ì†Œ ì„¤ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}\n\n"
                
                # êµ¬ê¸€ ì¥ì†Œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
                if place.google_info:
                    summary += "[êµ¬ê¸€ ì¥ì†Œ ì •ë³´]\n"
                    summary += f"ğŸ  ì£¼ì†Œ: {place.formatted_address or 'ì •ë³´ ì—†ìŒ'}\n"
                    summary += f"â­ í‰ì : {place.rating or 'None'}\n"
                    summary += f"ğŸ“ ì „í™”: {place.phone or 'None'}\n"
                    summary += f"ğŸŒ ì›¹ì‚¬ì´íŠ¸: {place.website or 'None'}\n"
                    summary += f"ğŸ’° ê°€ê²©ëŒ€: {'â‚©' * place.price_level if place.price_level else 'ì •ë³´ ì—†ìŒ'}\n"
                    
                    # ì˜ì—…ì‹œê°„
                    summary += "â° ì˜ì—…ì‹œê°„:\n"
                    if place.opening_hours:
                        for hours in place.opening_hours:
                            summary += f"{hours}\n"
                    else:
                        summary += "ì •ë³´ ì—†ìŒ\n"
                    
                    # ì‚¬ì§„ ë° ë¦¬ë·°
                    summary += "\n[ì‚¬ì§„ ë° ë¦¬ë·°]\n"
                    if place.photos:
                        for photo_idx, photo in enumerate(place.photos[:1], 1):
                            summary += f"ğŸ“¸ ì‚¬ì§„ {photo_idx}: {photo.url}\n"
                    summary += f"â­ ë² ìŠ¤íŠ¸ ë¦¬ë·°: {place.best_review or 'ë¦¬ë·° ì—†ìŒ'}\n"
                
                summary += "=" * 50 + "\n\n"
            
            summaries[content.url] = summary
        
        return summaries

    def _get_place_description_from_openai(self, place_name: str, place_type: str) -> str:
        """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì„¤ëª… ìƒì„±"""
        try:
            prompt = f"""ë‹¤ìŒ ì¥ì†Œì— ëŒ€í•œ ì •í™•í•˜ê³  ê°„ê²°í•œ ì„¤ëª…ì„ ì œê³µí•˜ì„¸ìš”.  
ì„¤ëª…ì€ 10ìë¡œ ì œí•œë˜ë©°, í•µì‹¬ ì •ë³´ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
ì¥ì†Œ: {place_name}
íƒ€ì…: {place_type}
ë°˜ë“œì‹œ ì§§ê³  ëª…í™•í•œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¼ë³¸ ì „ë¬¸ ì—¬í–‰ ê°€ì´ë“œì…ë‹ˆë‹¤. ì¥ì†Œì— ëŒ€í•œ ê°ê´€ì ì´ê³  ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=30
            )
            
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"ì¥ì†Œ ì„¤ëª… ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def process_place_info(self, place_name: str, timestamp: str, description: str) -> PlaceInfo:
        """PlaceServiceì˜ process_place_infoë¥¼ í˜¸ì¶œ"""
        return self.place_service.process_place_info(place_name, timestamp, description)

class YouTubeSubtitleService:
    """YouTube ìë§‰ ë° ë¹„ë””ì˜¤ ì •ë³´ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def get_video_info(video_url: str) -> Tuple[str, str]:
        try:
            video_id = video_url.split("v=")[-1].split("&")[0]
            api_url = f"https://noembed.com/embed?url=https://www.youtube.com/watch?v={video_id}"
            response = requests.get(api_url)
            if response.status_code == 200:
                data = response.json()
                title = data.get('title')
                author_name = data.get('author_name')
                print(f"[get_video_info] ì œëª©: {title}, ì±„ë„: {author_name}")
                return title, author_name
            print(f"[get_video_info] API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
            return None, None
        except Exception as e:
            print(f"ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            return None, None

    @staticmethod
    def process_link(url: str) -> str:
        link_type = YouTubeSubtitleService._detect_link_type(url)
        print(f"[process_link] ë§í¬ ìœ í˜• ê°ì§€: {link_type}")
        
        if link_type == "youtube":
            text = YouTubeSubtitleService._get_youtube_transcript(url)
        elif link_type == "text_file":
            text = YouTubeSubtitleService._get_text_from_file(url)
        else:
            text = YouTubeSubtitleService._get_text_from_webpage(url)
        
        print(f"[process_link] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")
        return text

    @staticmethod
    def _detect_link_type(url: str) -> str:
        if "youtube.com" in url or "youtu.be" in url:
            return "youtube"
        elif url.endswith(".txt"):
            return "text_file"
        elif url.startswith("http"):
            return "webpage"
        else:
            return "unknown"

    @staticmethod
    def _format_timestamp(seconds: float) -> str:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"

    @staticmethod
    def _get_youtube_transcript(video_url: str) -> str:
        video_id = video_url.split("v=")[-1].split("&")[0]
        print(f"[get_youtube_transcript] ë¹„ë””ì˜¤ ID: {video_id}")
        
        try:
            transcripts = YouTubeTranscriptApi.list_transcripts(video_id)
            
            # 1. ë¨¼ì € í•œêµ­ì–´ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_transcript(['ko'])
                transcript_text = "\n".join([f"[{YouTubeSubtitleService._format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] í•œêµ­ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except (TranscriptsDisabled, NoTranscriptFound):
                print("[get_youtube_transcript] í•œêµ­ì–´ ìë§‰ ì—†ìŒ.")

            # 2. ì˜ì–´ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_transcript(['en'])
                transcript_text = "\n".join([f"[{YouTubeSubtitleService._format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] ì˜ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except (TranscriptsDisabled, NoTranscriptFound):
                print("[get_youtube_transcript] ì˜ì–´ ìë§‰ ì—†ìŒ.")

            # 3. ì‚¬ìš© ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ ìë§‰ ì‹œë„
            try:
                transcript = transcripts.find_generated_transcript()
                transcript_text = "\n".join([f"[{YouTubeSubtitleService._format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript.fetch()])
                print(f"[get_youtube_transcript] ìƒì„±ëœ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
                return transcript_text
            except Exception as e:
                print(f"[get_youtube_transcript] ìƒì„±ëœ ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            raise ValueError(f"ë¹„ë””ì˜¤ {video_id}ì˜ ìë§‰ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

    @staticmethod
    def _get_text_from_file(url: str) -> str:
        try:
            response = requests.get(url)
            response.raise_for_status()
            text = response.text.strip()
            print(f"[get_text_from_file] í…ìŠ¤íŠ¸ íŒŒì¼ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(text)}")
            return text
        except Exception as e:
            raise ValueError(f"í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    @staticmethod
    def _get_text_from_webpage(url: str) -> str:
        try:
            response = requests.get(url)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, "html.parser")
            text = soup.get_text(separator="\n").strip()
            text = text[:10000]  # ê¸¸ì´ ì œí•œ 10000ì
            print(f"[get_text_from_webpage] ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(text)}")
            return text
        except Exception as e:
            raise ValueError(f"ì›¹í˜ì´ì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

class TextProcessingService:
    """í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    @staticmethod
    def split_text(text: str, max_chunk_size: int = CHUNK_SIZE) -> List[str]:
        words = text.split()
        total_words = len(words)
        num_chunks = ceil(total_words / (max_chunk_size // 5))
        chunks = []
        for i in range(num_chunks):
            start = i * (max_chunk_size // 5)
            end = start + (max_chunk_size // 5)
            chunk = ' '.join(words[start:end])
            chunks.append(chunk)
        print(f"[split_text] ì´ ë‹¨ì–´ ìˆ˜: {total_words}, ì²­í¬ ìˆ˜: {num_chunks}")
        return chunks

    @staticmethod
    def summarize_text(transcript_chunks: List[str], model: str = MODEL) -> str:
        summaries = []
        for idx, chunk in enumerate(transcript_chunks):
            prompt = TextProcessingService._generate_prompt(chunk)
            try:
                response = openai.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "You are a travel expert who provides detailed recommendations for places to visit, foods to eat, precautions, and suggestions based on transcripts."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,
                    max_tokens=1500
                )
                summary = response.choices[0].message.content
                summaries.append(summary)
                print(f"ì²­í¬ {idx+1}/{len(transcript_chunks)} ìš”ì•½ ì™„ë£Œ.")
                print(f"[ì²­í¬ {idx+1} ìš”ì•½ ë‚´ìš© ì¼ë¶€]")
                print(summary[:9500])
            except Exception as e:
                raise ValueError(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ê°œë³„ ìš”ì•½ì„ í•©ì³ì„œ ìµœì¢… ìš”ì•½
        combined_summaries = "\n".join(summaries)
        final_prompt = f"""
ì•„ë˜ëŠ” ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ë‰œ ìš”ì•½ì…ë‹ˆë‹¤. ì´ ìš”ì•½ë“¤ì„ í†µí•©í•˜ì—¬ ë‹¤ìŒì˜ í˜•ì‹ìœ¼ë¡œ ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ê³ , ë¹ ì§€ëŠ” ë‚´ìš© ì—†ì´ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
**ìš”êµ¬ ì‚¬í•­:**
1. ì¥ì†Œ, ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ ë“± ê°ê°ì˜ ì •ë³´ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
2. ë§Œì•½ í•´ë‹¹ ì¥ì†Œì—ì„œ ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì´ ì—†ë‹¤ë©´ ì‘ì„±í•˜ì§€ ì•Šê³  ë„˜ì–´ê°€ë„ ë©ë‹ˆë‹¤.
3. ë°©ë¬¸í•œ ì¥ì†Œê°€ ì—†ê±°ë‚˜ ìœ ì˜ ì‚¬í•­ë§Œ ìˆì„ ë•Œ, ìœ ì˜ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
4. ì¶”ì²œ ì‚¬í•­ë§Œ ìˆëŠ” ê²ƒë“¤ì€ ì¶”ì²œ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
5. ê°€ëŠ¥í•œ ì¥ì†Œ ì´ë¦„ì„ ì•Œê³  ìˆë‹¤ë©´ ì‹¤ì œ ì£¼ì†Œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
7. ë³¸ë¬¸ ë‚´ì— ì–¸ê¸‰ëœ ëª¨ë“  ì¥ì†Œ (ì˜ˆ: "ë„ì¿„ í•´ë¦¬í¬í„° ìŠ¤íŠœë””ì˜¤", "ë…¸ë³´ë¦¬ë² ì¸ " ë“±)ë¥¼ ë°˜ë“œì‹œ ê²°ê³¼ì— í¬í•¨ì‹œì¼œ ì£¼ì„¸ìš”.
8. ì£¼ì†Œê°€ í¬í•¨ëœ ê²½ìš° ì´ë¥¼ ì œì™¸í•˜ê³ , ì¼ë³¸ ë‚´ ì¥ì†Œë§Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤. "ì•¼í‚¤í† ë¦¬ì§‘"ì´ë¼ê³ ë§Œ ì–¸ê¸‰ëœ ê²½ìš°ì—ëŠ” ì˜¤ì‚¬ì¹´ ë‚´ì˜ ì•¼í‚¤í† ë¦¬ì§‘ ì¤‘ í•˜ë‚˜ì˜ ì£¼ì†Œë¥¼ ì°¾ì•„ì„œ ì œê³µí•´ ì£¼ì„¸ìš”.
9. ì•„ì¹´íƒ€ ìƒ¤ë¸Œìƒ¤ë¸Œ"ì™€ ê°™ì´ ëª…í™•í•œ ë¸Œëœë“œëª…ì´ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ê²½ìš°, ì§€ì—­ ë‚´ ì í•©í•œ ìƒ¤ë¸Œìƒ¤ë¸Œì§‘ ì£¼ì†Œë¥¼ ì°¾ì•„ì„œ ì œê³µí•´ ì£¼ì„¸ìš”.

**ê²°ê³¼ í˜•ì‹:**

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”
ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 

ë°©ë¬¸í•œ ì¥ì†Œ: ìŠ¤ë¯¸ë‹¤ íƒ€ì›Œ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ë„ì¿„ ìŠ¤ì¹´ì´íŠ¸ë¦¬ë¥¼ ëŒ€í‘œí•˜ëŠ” ëœë“œë§ˆí¬ë¡œ, ì „ë§ëŒ€ì—ì„œ ë„ì¿„ ì‹œë‚´ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” ë‚ ì”¨ê°€ ì¢‹ì•„ì„œ í›„ì§€ì‚°ê¹Œì§€ ë³´ì˜€ê³ , ì•¼ê²½ì´ íŠ¹íˆ ì•„ë¦„ë‹¤ì› ë‹¤ê³  í•©ë‹ˆë‹¤.
- ë¨¹ì€ ìŒì‹: ë¼ë©˜ ì´ì¹˜ë€
    - ì„¤ëª…: ì§„í•œ êµ­ë¬¼ê³¼ ì«„ê¹ƒí•œ ë©´ë°œë¡œ ìœ ëª…í•œ ë¼ë©˜ ì²´ì¸ì ìœ¼ë¡œ, ê°œì¸ì‹¤ì—ì„œ í¸ì•ˆí•˜ê²Œ ì‹ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: í˜¼ì¡í•œ ì‹œê°„ëŒ€ í”¼í•˜ê¸°
    - ì„¤ëª…: ê´€ê´‘ì§€ ì£¼ë³€ì€ íŠ¹íˆ ì£¼ë§ê³¼ íœ´ì¼ì— ë§¤ìš° í˜¼ì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°€ëŠ¥í•œ í‰ì¼ì´ë‚˜ ì´ë¥¸ ì‹œê°„ì— ë°©ë¬¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì¶”ì²œ ì‚¬í•­: ìŠ¤ì¹´ì´ íŠ¸ë¦¬ ì „ë§ëŒ€ ë°©ë¬¸
    - ì„¤ëª…: ë„ì¿„ì˜ ì•„ë¦„ë‹¤ìš´ ì•¼ê²½ì„ ê°ìƒí•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ì§„ ì´¬ì˜ í•˜ê¸°ì— ìµœì ì˜ ì¥ì†Œì…ë‹ˆë‹¤.

ë°©ë¬¸í•œ ì¥ì†Œ: ìœ ë‹ˆë²„ì…œ ìŠ¤íŠœë””ì˜¤ ì¼ë³¸ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” í‰ì¼ì„ì—ë„ ì‚¬ëŒì´ ë§ì•˜ì§€ë§Œ, ì‹±ê¸€ë¼ì´ë”ë¥¼ ì´ìš©í•´ì„œ ëŒ€ê¸° ì‹œê°„ì„ ë§ì´ ì¤„ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•´ë¦¬í¬í„° êµ¬ì—­ì˜ ë¶„ìœ„ê¸°ê°€ ì‹¤ì œ ì˜í™”ì˜ í•œ ì¥ë©´ì— ë“¤ì–´ì˜¨ ê²ƒ ê°™ì•˜ê³ , ë²„í„°ë§¥ì£¼ë„ ë§›ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: ì§§ì€ ì˜· ì°©ìš© 
    - ì„¤ëª…: íŒ€ë© í”Œë˜ë‹›ì˜ ì¼ë¶€ êµ¬ì—­ì—ì„œëŠ” ë¬¼ì´ ë†’ê³  ê±°ìš¸ì´ ìˆìœ¼ë¯€ë¡œ, ì§§ì€ ì˜·ì„ ì…ëŠ” ê²ƒì´ ì¢‹ë‹¤.

**ìš”ì•½ ì²­í¬:**
{combined_summaries}

**ìµœì¢… ìš”ì•½:**
"""
        try:
            final_response = openai.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are an expert summary writer who strictly adheres to the provided format."},
                    {"role": "user", "content": final_prompt}
                ],
                temperature=0.1,
                max_tokens=4096
            )
            final_summary = final_response.choices[0].message.content
            print("\n[ìµœì¢… ìš”ì•½ ë‚´ìš© ì¼ë¶€]")
            print(final_summary[:1000])
            return final_summary
        except Exception as e:
            raise ValueError(f"ìµœì¢… ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    @staticmethod
    def _generate_prompt(transcript_chunk: str) -> str:
        language = detect(transcript_chunk)
        if language != 'ko':
            translation_instruction = "ì´ í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ê°€ ì•„ë‹™ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ ì£¼ì„¸ìš”.\n\n"
        else:
            translation_instruction = ""

        base_prompt = f"""
{translation_instruction}
ì•„ë˜ëŠ” ì—¬í–‰ ìœ íŠœë²„ê°€ ì´¬ì˜í•œ ì˜ìƒì˜ ìë§‰ì…ë‹ˆë‹¤. ì´ ìë§‰ì—ì„œ ë°©ë¬¸í•œ ì¥ì†Œ, ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

**ìš”êµ¬ ì‚¬í•­:**
1. ì¥ì†Œ, ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ ë“± ê°ê°ì˜ ì •ë³´ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
2. ë§Œì•½ í•´ë‹¹ ì¥ì†Œì—ì„œ ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì´ ì—†ë‹¤ë©´ ì‘ì„±í•˜ì§€ ì•Šê³  ë„˜ì–´ê°€ë„ ë©ë‹ˆë‹¤.
3. ë°©ë¬¸í•œ ì¥ì†Œê°€ ì—†ê±°ë‚˜ ìœ ì˜ ì‚¬í•­ë§Œ ìˆì„ ë•Œ, ìœ ì˜ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
4. ì¶”ì²œ ì‚¬í•­ë§Œ ìˆëŠ” ê²ƒë“¤ì€ ì¶”ì²œ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
5. ê°€ëŠ¥í•œ ì¥ì†Œ ì´ë¦„ì„ ì•Œê³  ìˆë‹¤ë©´ ì‹¤ì œ ì£¼ì†Œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
6. ì¥ì†Œ ì„¤ëª…ì€ ë°˜ë“œì‹œ ìœ íŠœë²„ê°€ ì‹¤ì œë¡œ ì–¸ê¸‰í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ìœ íŠœë²„ì˜ ì‹¤ì œ ê²½í—˜ê³¼ í‰ê°€ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
7. ë³¸ë¬¸ ë‚´ì— ì–¸ê¸‰ëœ ëª¨ë“  ì¥ì†Œ (ì˜ˆ: "ë„ì¿„ í•´ë¦¬í¬í„° ìŠ¤íŠœë””ì˜¤", "ë…¸ë³´ë¦¬ë² ì¸ " ë“±)ë¥¼ ë°˜ë“œì‹œ ê²°ê³¼ì— í¬í•¨ì‹œì¼œ ì£¼ì„¸ìš”.

**ê²°ê³¼ í˜•ì‹:**

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”
ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 

ë°©ë¬¸í•œ ì¥ì†Œ: ìŠ¤ë¯¸ë‹¤ íƒ€ì›Œ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ë„ì¿„ ìŠ¤ì¹´ì´íŠ¸ë¦¬ë¥¼ ëŒ€í‘œí•˜ëŠ” ëœë“œë§ˆí¬ë¡œ, ì „ë§ëŒ€ì—ì„œ ë„ì¿„ ì‹œë‚´ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” ë‚ ì”¨ê°€ ì¢‹ì•„ì„œ í›„ì§€ì‚°ê¹Œì§€ ë³´ì˜€ê³ , ì•¼ê²½ì´ íŠ¹íˆ ì•„ë¦„ë‹¤ì› ë‹¤ê³  í•©ë‹ˆë‹¤.
- ë¨¹ì€ ìŒì‹: ë¼ë©˜ ì´ì¹˜ë€
    - ì„¤ëª…: ì§„í•œ êµ­ë¬¼ê³¼ ì«„ê¹ƒí•œ ë©´ë°œë¡œ ìœ ëª…í•œ ë¼ë©˜ ì²´ì¸ì ìœ¼ë¡œ, ê°œì¸ì‹¤ì—ì„œ í¸ì•ˆí•˜ê²Œ ì‹ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: í˜¼ì¡í•œ ì‹œê°„ëŒ€ í”¼í•˜ê¸°
    - ì„¤ëª…: ê´€ê´‘ì§€ ì£¼ë³€ì€ íŠ¹íˆ ì£¼ë§ê³¼ íœ´ì¼ì— ë§¤ìš° í˜¼ì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°€ëŠ¥í•œ í‰ì¼ì´ë‚˜ ì´ë¥¸ ì‹œê°„ì— ë°©ë¬¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì¶”ì²œ ì‚¬í•­: ìŠ¤ì¹´ì´ íŠ¸ë¦¬ ì „ë§ëŒ€ ë°©ë¬¸
    - ì„¤ëª…: ë„ì¿„ì˜ ì•„ë¦„ë‹¤ìš´ ì•¼ê²½ì„ ê°ìƒí•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ì§„ ì´¬ì˜ í•˜ê¸°ì— ìµœì ì˜ ì¥ì†Œì…ë‹ˆë‹¤.

ë°©ë¬¸í•œ ì¥ì†Œ: ìœ ë‹ˆë²„ì…œ ìŠ¤íŠœë””ì˜¤ ì¼ë³¸ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” í‰ì¼ì„ì—ë„ ì‚¬ëŒì´ ë§ì•˜ì§€ë§Œ, ì‹±ê¸€ë¼ì´ë”ë¥¼ ì´ìš©í•´ì„œ ëŒ€ê¸° ì‹œê°„ì„ ë§ì´ ì¤„ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•´ë¦¬í¬í„° êµ¬ì—­ì˜ ë¶„ìœ„ê¸°ê°€ ì‹¤ì œ ì˜í™”ì˜ í•œ ì¥ë©´ì— ë“¤ì–´ì˜¨ ê²ƒ ê°™ì•˜ê³ , ë²„í„°ë§¥ì£¼ë„ ë§›ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: ì§§ì€ ì˜· ì°©ìš© 
    - ì„¤ëª…: íŒ€ë© í”Œë˜ë‹›ì˜ ì¼ë¶€ êµ¬ì—­ì—ì„œëŠ” ë¬¼ì´ ë†’ê³  ê±°ìš¸ì´ ìˆìœ¼ë¯€ë¡œ, ì§§ì€ ì˜·ì„ ì…ëŠ” ê²ƒì´ ì¢‹ë‹¤.

**ìë§‰:**
{transcript_chunk}

ìœ„ ìë§‰ì„ ë°”íƒ•ìœ¼ë¡œ ìœ„ì˜ ìš”êµ¬ ì‚¬í•­ì— ë§ëŠ” ì •ë³´ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. íŠ¹íˆ ì¥ì†Œ ì„¤ëª…ì€ ë°˜ë“œì‹œ ìœ íŠœë²„ê°€ ì‹¤ì œë¡œ ì–¸ê¸‰í•œ ë‚´ìš©ê³¼ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""
        print("\n[generate_prompt] ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì¼ë¶€:")
        print(base_prompt[:500])
        return base_prompt

class PlaceService:
    """ì¥ì†Œ ì •ë³´ ì²˜ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.video_url = None

    def set_video_url(self, url: str):
        self.video_url = url

    def extract_place_names(self, summary: str) -> List[str]:
        """ìš”ì•½ í…ìŠ¤íŠ¸ì—ì„œ ì¥ì†Œ ì´ë¦„ì„ ì¶”ì¶œ"""
        place_names = set()  # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ set ì‚¬ìš©
        
        # ëª¨ë“  ì²­í¬ì˜ ìš”ì•½ì—ì„œ ì¥ì†Œ ì¶”ì¶œ
        chunks = summary.split("ë°©ë¬¸í•œ ì¥ì†Œ:")
        for chunk in chunks[1:]:  # ì²« ë²ˆì§¸ëŠ” ê±´ë„ˆë›°ê¸°
            try:
                place_name = chunk.split("(")[0].strip()
                if place_name:
                    place_names.add(place_name)
                    print(f"ì¥ì†Œ ì¶”ì¶œ: {place_name}")
            except Exception as e:
                print(f"ì¥ì†Œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                continue
        
        result = list(place_names)
        print(f"ì´ ì¶”ì¶œëœ ì¥ì†Œ ëª©ë¡: {result}")
        return result

    @staticmethod
    def search_place_details(place_name: str) -> Dict[str, Any]:
        """Google Places APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ì •ë³´ë¥¼ ê²€ìƒ‰"""
        try:
            gmaps = googlemaps.Client(key=os.getenv("GOOGLE_PLACES_API_KEY"))
            
            # ì¥ì†Œ ê²€ìƒ‰
            places_result = gmaps.places(place_name)
            
            if not places_result['results']:
                print(f"[search_place_details] ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {place_name}")
                return None
                
            place = places_result['results'][0]
            place_id = place['place_id']
            
            # ìƒì„¸ ì •ë³´ ê²€ìƒ‰
            details_result = gmaps.place(place_id, language='ko')
            if not details_result.get('result'):
                return None
                
            details = details_result['result']
            
            # ë¦¬ë·° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            reviews = details.get('reviews', [])
            best_review = reviews[0]['text'] if reviews else None
            
            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            return {
                'name': details.get('name', ''),
                'formatted_address': details.get('formatted_address', ''),
                'rating': details.get('rating'),
                'formatted_phone_number': details.get('formatted_phone_number', ''),
                'website': details.get('website', ''),
                'price_level': details.get('price_level'),
                'opening_hours': details.get('opening_hours', {}).get('weekday_text', []),
                'photos': details.get('photos', []),
                'best_review': best_review
            }
            
        except Exception as e:
            print(f"[search_place_details] ì¥ì†Œ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({place_name}): {str(e)}")
            return None

    @staticmethod
    def get_place_photo_google(place_name: str) -> str:
        """Google Places APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ì‚¬ì§„ URLì„ ê°€ì ¸ì˜´"""
        try:
            gmaps = googlemaps.Client(key=os.getenv("GOOGLE_PLACES_API_KEY"))
            places_result = gmaps.places(place_name)
            
            if not places_result['results']:
                print(f"[get_place_photo_google] ì‚¬ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {place_name}")
                return None
                
            place = places_result['results'][0]
            if not place.get('photos'):
                return None
                
            photo_reference = place['photos'][0]['photo_reference']
            photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_reference}&key={os.getenv('GOOGLE_PLACES_API_KEY')}"
            
            print(f"[get_place_photo_google] ì‚¬ì§„ URL ìƒì„± ì™„ë£Œ: {photo_url}")
            return photo_url
            
        except Exception as e:
            print(f"[get_place_photo_google] ì‚¬ì§„ URL ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def process_place_info(self, place_name: str, timestamp: str, description: str) -> PlaceInfo:
        """ì¥ì†Œ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ê³  PlaceInfo ê°ì²´ë¥¼ ë°˜í™˜"""
        try:
            # Google Places APIë¡œ ì¥ì†Œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            gmaps = googlemaps.Client(key=os.getenv("GOOGLE_PLACES_API_KEY"))
            places_result = gmaps.places(place_name)
            
            if not places_result['results']:
                return None
            
            google_place_info = places_result['results'][0]
            
            # ì‚¬ì§„ URL ê°€ì ¸ì˜¤ê¸°
            photo_url = self.get_place_photo_google(place_name)
            
            # ì¥ì†Œ íƒ€ì… í™•ì¸
            place_type = google_place_info.get('types', ['unknown'])[0]
            
            # OpenAIë¡œ ê³µì‹ ì„¤ëª… ìƒì„±
            official_description = self._get_place_description_from_openai(place_name, place_type)
            
            # ì˜ì—…ì‹œê°„ í¬ë§·íŒ…
            opening_hours = None
            if google_place_info.get('opening_hours'):
                opening_hours = google_place_info['opening_hours'].get('weekday_text')

            # PlaceInfo ê°ì²´ ìƒì„±
            place_info = PlaceInfo(
                name=place_name,
                source_url=self.video_url,
                timestamp=timestamp,
                description=description,
                official_description=official_description,
                formatted_address=google_place_info.get('formatted_address'),
                coordinates={
                    'lat': google_place_info['geometry']['location']['lat'],
                    'lng': google_place_info['geometry']['location']['lng']
                } if 'geometry' in google_place_info else None,
                rating=google_place_info.get('rating'),
                phone=google_place_info.get('formatted_phone_number'),
                website=google_place_info.get('website'),
                price_level=google_place_info.get('price_level'),
                opening_hours=opening_hours,
                photos=[PlacePhoto(url=photo_url)] if photo_url else None,
                best_review=google_place_info.get('reviews', [{}])[0].get('text') if google_place_info.get('reviews') else None,
                google_info=google_place_info,
                types=google_place_info.get('types')
            )
            
            return place_info
            
        except Exception as e:
            print(f"ì¥ì†Œ ì •ë³´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
