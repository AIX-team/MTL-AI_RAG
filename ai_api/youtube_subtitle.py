import os
import requests
import datetime
import time
import tiktoken  # í† í° ìˆ˜ ê³„ì‚°ì„ ìœ„í•´ tiktoken ì‚¬ìš©
from math import ceil
from langdetect import detect
from dotenv import load_dotenv
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound
from bs4 import BeautifulSoup
import openai
from googleapiclient.discovery import build
import googlemaps
from typing import Dict, Any

# -------------------
# 0. í™˜ê²½ ë³€ìˆ˜ ë° ìƒìˆ˜ ì„¤ì •
# -------------------

# .env íŒŒì¼ ë¡œë“œ
load_dotenv(dotenv_path=".env")  # .env íŒŒì¼ ê²½ë¡œ í™•ì¸

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = os.getenv("OPENAI_API_KEY")
print(f"OpenAI API Key: {'ì„¤ì •ë¨' if openai.api_key else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")  # ë””ë²„ê¹…ìš©

# êµ¬ê¸€ API í‚¤ ì„¤ì •
GEOCODING_API_KEY = os.getenv("GOOGLE_GEOCODING_API_KEY")
GOOGLE_PLACES_API_KEY = os.getenv("GOOGLE_PLACES_API_KEY")
print(f"Google Geocoding API Key: {'ì„¤ì •ë¨' if GEOCODING_API_KEY else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")  # ë””ë²„ê¹…ìš©
print(f"Google Places API Key: {'ì„¤ì •ë¨' if GOOGLE_PLACES_API_KEY else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")  # ë””ë²„ê¹…ìš©

# ì‚¬ìš©í•  ìƒìˆ˜ë“¤
MAX_URLS = 5  # ìµœëŒ€ URL ê°œìˆ˜
CHUNK_SIZE = 2048  # ê° í…ìŠ¤íŠ¸ ì²­í¬ì˜ ìµœëŒ€ í† í° ìˆ˜ (ì¡°ì • ê°€ëŠ¥)
MODEL = "gpt-4o"  # ì‚¬ìš©í•  OpenAI ëª¨ë¸
FINAL_SUMMARY_MAX_TOKENS = 1500  # ìµœì¢… ìš”ì•½ì˜ ìµœëŒ€ í† í° ìˆ˜

# -------------------
# 1. ë©”ì¸ ì‹¤í–‰ íë¦„
# -------------------
def process_urls(urls):
    start_time = time.time()
    all_text = ""
    video_infos = []
    
    # (1) ì…ë ¥ë°›ì€ URLì„ ìˆœíšŒí•˜ë©´ì„œ í…ìŠ¤íŠ¸/ìë§‰ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    for idx, url in enumerate(urls, 1):
        print(f"\nURL {idx}/{len(urls)} ì²˜ë¦¬ ì¤‘: {url}")
        try:
            # 1-1) ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            video_title, channel_name = get_video_info(url)
            if video_title and channel_name:
                video_infos.append({
                    'url': url,
                    'title': video_title,
                    'channel': channel_name
                })
                print(f"ì˜ìƒ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ: ì œëª©='{video_title}', ì±„ë„='{channel_name}'")
            else:
                print("ì˜ìƒ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨.")
            
            # 1-2) URLì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì–»ìŠµë‹ˆë‹¤.
            text = process_link(url)
            all_text += f"\n\n--- URL {idx} ë‚´ìš© ---\n{text}"
            print(f"URL {idx} í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ.")
        except Exception as e:
            print(f"URL {idx} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # (2) ëª¨ë“  URLì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì œëŒ€ë¡œ ì¶”ì¶œí•˜ì§€ ëª»í–ˆë‹¤ë©´ ì—ëŸ¬ ë°œìƒ
    if not all_text.strip():
        raise ValueError("ëª¨ë“  URLì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # (3) ì¶”ì¶œëœ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ CHUNK_SIZEì— ë§ê²Œ ë¶„í• í•©ë‹ˆë‹¤.
    print("\ní…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  ì¤‘...")
    transcript_chunks = split_text(all_text)
    print(f"í…ìŠ¤íŠ¸ê°€ {len(transcript_chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # (4) ë¶„í• ëœ ì²­í¬ë¥¼ íŒŒì¼ë¡œ ì €ì¥(ë””ë²„ê¹…/ê²€ì¦ ìš©ë„)
    save_chunks(transcript_chunks)
    
    # (5) ë‚˜ëˆ ì§„ ì²­í¬ë“¤ì„ ìš”ì•½í•©ë‹ˆë‹¤.
    print("\nìš”ì•½ì„ ìƒì„± ì¤‘...")
    final_summary = summarize_text(transcript_chunks)
    
    # (6) ìš”ì•½ì—ì„œ ë°©ë¬¸ ì¥ì†Œëª…ì„ ì¶”ì¶œí•˜ê³ , ì¶”ê°€ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    print("\nì¥ì†Œ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
    place_details = []
    place_names = extract_place_names(final_summary)
    
    print(f"ì¶”ì¶œëœ ì¥ì†Œ ì´ë¦„: {place_names}")  # ë””ë²„ê¹… ì¶œë ¥
    
    for place_name in place_names:
        print(f"\n{place_name} ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        details = {}
        
        # (6-1) Google Places APIë¡œ ì¥ì†Œ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        try:
            google_details = search_place_details(place_name)
            if google_details:
                details.update(google_details)
                print(f"{place_name}ì˜ Google Places API ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ.")
                
                # (6-2) ê°€ì ¸ì˜¨ place_nameìœ¼ë¡œ ì‚¬ì§„ URLë„ í•¨ê»˜ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
                photo_url = get_place_photo_google(place_name, GOOGLE_PLACES_API_KEY)
                if photo_url and photo_url not in ["ì‚¬ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "API ìš”ì²­ ì‹¤íŒ¨."]:
                    details['photos'] = [{
                        'url': photo_url,
                        'title': f'{place_name} ì‚¬ì§„',
                        'description': f'{place_name}ì˜ Google Places APIë¥¼ í†µí•´ ê°€ì ¸ì˜¨ ì‚¬ì§„ì…ë‹ˆë‹¤.'
                    }]
                    print(f"{place_name}ì˜ ì‚¬ì§„ URL ìˆ˜ì§‘ ì™„ë£Œ.")
                else:
                    print(f"{place_name}ì˜ ì‚¬ì§„ URL ìˆ˜ì§‘ ì‹¤íŒ¨: {photo_url}")
        except Exception as e:
            print(f"Google Places API ì˜¤ë¥˜: {e}")
        
        if details:
            place_details.append(details)
            print(f"{place_name}ì˜ ìƒì„¸ ì •ë³´ê°€ place_detailsì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"{place_name}ì˜ ìƒì„¸ ì •ë³´ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # (7) ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    end_time = time.time()
    processing_time = end_time - start_time
    
    # (8) ìµœì¢… ê²°ê³¼ë¥¼ ë¬¸ìì—´ í˜•íƒœë¡œ êµ¬ì„±
    final_result = f"""
=== ì—¬í–‰ ì •ë³´ ìš”ì•½ ===
ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ

ë¶„ì„í•œ ì˜ìƒ:
{'='*50}"""
    
    # 8-1) ìˆ˜ì§‘ëœ ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´ ì¶œë ¥ìš©
    if video_infos:
        for info in video_infos:
            final_result += f"""
ì œëª©: {info['title']}
ì±„ë„: {info['channel']}
URL: {info['url']}"""
    else:
        final_result += f"""
URL: {chr(10).join(urls)}"""
    
    final_result += f"\n{'='*50}\n"

    # (9) ì¥ì†Œë³„ ì •ë³´ í†µí•©(ìœ íŠœë¸Œ ìš”ì•½ë‚´ìš© + êµ¬ê¸€ ì •ë³´)
    places_info = {}
    for line in final_summary.split('\n'):
        # ë°©ë¬¸í•œ ì¥ì†Œ íŒŒì‹±
        if line.startswith('ë°©ë¬¸í•œ ì¥ì†Œ:'):
            place_name = line.split('(')[0].replace('ë°©ë¬¸í•œ ì¥ì†Œ:', '').strip()
            if place_name not in places_info:
                places_info[place_name] = {'youtuber_info': [], 'google_info': None}
            
            start_idx = final_summary.find(line)
            end_idx = final_summary.find("\n\në°©ë¬¸í•œ ì¥ì†Œ:", start_idx)
            if end_idx == -1:
                end_idx = len(final_summary)
            place_section = final_summary[start_idx:end_idx]
            
            places_info[place_name]['youtuber_info'] = place_section.split('\n')
    
    # (10) Google Places API ì •ë³´ì™€ ë§¤ì¹­
    for place in place_details:
        place_name = place.get('name')
        if place_name in places_info:
            places_info[place_name]['google_info'] = place
            print(f"{place_name}ì˜ Google Places ì •ë³´ê°€ places_infoì— ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # (11) ì¥ì†Œë³„ ìƒì„¸ ì •ë³´ ë¬¸ìì—´ì— ì¶”ê°€
    final_result += "\n=== ì¥ì†Œë³„ ìƒì„¸ ì •ë³´ ===\n"
    
    for idx, (place_name, info) in enumerate(places_info.items(), 1):
        final_result += f"\n{idx}. {place_name}\n{'='*50}\n"
        
        # 11-1) ìœ íŠœë²„ ì •ë³´
        if info['youtuber_info']:
            final_result += "\n[ìœ íŠœë²„ì˜ ë¦¬ë·°]\n"
            
            place_desc = ""
            foods = []
            precautions = []
            recommendations = []
            
            for line in info['youtuber_info']:
                line = line.strip()
                if not line or line.startswith('ë°©ë¬¸í•œ ì¥ì†Œ:'):
                    continue
                    
                if line.startswith('- ì¥ì†Œì„¤ëª…:'):
                    place_desc = line.replace('- ì¥ì†Œì„¤ëª…:', '').strip()
                elif line.startswith('- ë¨¹ì€ ìŒì‹:'):
                    foods.append(line.replace('- ë¨¹ì€ ìŒì‹:', '').strip())
                elif line.startswith('- ìœ ì˜ ì‚¬í•­:'):
                    precautions.append(line.replace('- ìœ ì˜ ì‚¬í•­:', '').strip())
                elif line.startswith('- ì¶”ì²œ ì‚¬í•­:'):
                    recommendations.append(line.replace('- ì¶”ì²œ ì‚¬í•­:', '').strip())
                elif line.startswith('\t- ì„¤ëª…:'):
                    description = line.replace('\t- ì„¤ëª…:', '').strip()
                    if foods and not description.startswith('- '):
                        foods[-1] += f"\n  ì„¤ëª…: {description}"
                    elif precautions and not description.startswith('- '):
                        precautions[-1] += f"\n  ì„¤ëª…: {description}"
                    elif recommendations and not description.startswith('- '):
                        recommendations[-1] += f"\n  ì„¤ëª…: {description}"
            
            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¶œë ¥
            if place_desc:
                final_result += f"ì¥ì†Œì„¤ëª…: {place_desc}\n"
            
            if foods:
                final_result += "\n[ë¨¹ì€ ìŒì‹]\n"
                for food in foods:
                    final_result += f"- {food}\n"
            
            if precautions:
                final_result += "\n[ìœ ì˜ ì‚¬í•­]\n"
                for precaution in precautions:
                    final_result += f"- {precaution}\n"
            
            if recommendations:
                final_result += "\n[ì¶”ì²œ ì‚¬í•­]\n"
                for recommendation in recommendations:
                    final_result += f"- {recommendation}\n"
        
        # 11-2) êµ¬ê¸€ ì •ë³´
        if info['google_info']:
            google_info = info['google_info']
            opening_hours = google_info.get('opening_hours', ['ì •ë³´ ì—†ìŒ'])
            if not isinstance(opening_hours, list):
                opening_hours = ['ì •ë³´ ì—†ìŒ']

            final_result += f"""
[êµ¬ê¸€ ì¥ì†Œ ì •ë³´]
ğŸ  ì£¼ì†Œ: {google_info.get('formatted_address', 'ì •ë³´ ì—†ìŒ')}
â­ í‰ì : {google_info.get('rating', 'ì •ë³´ ì—†ìŒ')}
ğŸ“ ì „í™”: {google_info.get('phone', 'ì •ë³´ ì—†ìŒ')}
ğŸŒ ì›¹ì‚¬ì´íŠ¸: {google_info.get('website', 'ì •ë³´ ì—†ìŒ')}
ğŸ’° ê°€ê²©ëŒ€: {'â‚©' * google_info.get('price_level', 0) if google_info.get('price_level') else 'ì •ë³´ ì—†ìŒ'}
â° ì˜ì—…ì‹œê°„:
{chr(10).join(opening_hours)}

[ì‚¬ì§„ ë° ë¦¬ë·°]"""
                    
            if 'photos' in google_info and google_info['photos']:
                for photo_idx, photo in enumerate(google_info['photos'], 1):
                    final_result += f"""
ğŸ“¸ ì‚¬ì§„ {photo_idx}: {photo['url']}
â­ ë² ìŠ¤íŠ¸ ë¦¬ë·°: {google_info.get('best_review', {}).get('text', 'ë¦¬ë·° ì—†ìŒ') if google_info.get('best_review') else 'ë¦¬ë·° ì—†ìŒ'}"""
            else:
                final_result += "\nì‚¬ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        final_result += f"\n{'='*50}"
    
    # (12) ìµœì¢… ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
    save_final_summary(final_result)
    return {
        'final_summary': final_result,
        'video_infos': video_infos,
        'processing_time_seconds': processing_time
    }


# -------------------
# 2. ë©”ì¸ì—ì„œ í˜¸ì¶œë˜ëŠ” í•µì‹¬ í•¨ìˆ˜: process_urls
# -------------------
def get_video_info(video_url):
    """
    YouTube ì˜ìƒì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. 
    ì˜ìƒ ì œëª©, ì±„ë„ëª… ë“±ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ noembed APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        video_id = video_url.split("v=")[-1].split("&")[0]
        api_url = f"https://noembed.com/embed?url=https://www.youtube.com/watch?v={video_id}"
        response = requests.get(api_url)
        if response.status_code == 200:
            data = response.json()
            title = data.get('title')
            author_name = data.get('author_name')
            print(f"[get_video_info] ì œëª©: {title}, ì±„ë„: {author_name}")  # ë””ë²„ê¹… ì¶œë ¥
            return title, author_name
        print(f"[get_video_info] API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
        return None, None
    except Exception as e:
        print(f"ì˜ìƒ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None


# -------------------
# 3. ë©”ì¸ -> process_urls -> process_link
# -------------------
def process_link(url):
    """
    ë§í¬ ìœ í˜•ì— ë”°ë¼(ìœ íŠœë¸Œ, í…ìŠ¤íŠ¸ íŒŒì¼, ì›¹í˜ì´ì§€) 
    ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    link_type = detect_link_type(url)
    print(f"[process_link] ë§í¬ ìœ í˜• ê°ì§€: {link_type}")  # ë””ë²„ê¹… ì¶œë ¥
    
    if link_type == "youtube":
        text = get_youtube_transcript(url)
    elif link_type == "text_file":
        text = get_text_from_file(url)
    else:  # ì›¹í˜ì´ì§€
        text = get_text_from_webpage(url)
    
    print(f"[process_link] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}")  # ë””ë²„ê¹… ì¶œë ¥
    return text


# -------------------
# 4. process_link -> detect_link_type
# -------------------
def detect_link_type(url):
    """ë§í¬ ìœ í˜• ê°ì§€"""
    if "youtube.com" in url or "youtu.be" in url:
        return "youtube"
    elif url.endswith(".txt"):
        return "text_file"
    elif url.startswith("http"):
        return "webpage"
    else:
        return "unknown"


# -------------------
# 5. process_link -> get_youtube_transcript
# -------------------
def get_youtube_transcript(video_url):
    """
    YouTube ìë§‰ ì¶”ì¶œ ë° íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨.
    í•œêµ­ì–´ ìë§‰ ìš°ì„  -> ì˜ì–´ ìë§‰ -> ê¸°íƒ€ ì–¸ì–´ ìë§‰ ìˆœìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.
    """
    video_id = video_url.split("v=")[-1].split("&")[0]  # ë¹„ë””ì˜¤ ID ì¶”ì¶œ
    print(f"[get_youtube_transcript] ë¹„ë””ì˜¤ ID: {video_id}")  # ë””ë²„ê¹… ì¶œë ¥
    try:
        transcripts = YouTubeTranscriptApi.list_transcripts(video_id)
        # ìš°ì„  í•œêµ­ì–´ ìë§‰ ì‹œë„
        if transcripts.find_transcript(['ko']):
            transcript = transcripts.find_transcript(['ko']).fetch()
            transcript_text = "\n".join([f"[{format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript])
            print(f"[get_youtube_transcript] í•œêµ­ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
            return transcript_text
    except (TranscriptsDisabled, NoTranscriptFound):
        print("[get_youtube_transcript] í•œêµ­ì–´ ìë§‰ ì—†ìŒ.")
        pass
    except Exception as e:
        raise ValueError(f"ë¹„ë””ì˜¤ {video_id}ì˜ ìë§‰ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

    try:
        # ì˜ì–´ ìë§‰ ì‹œë„
        if transcripts.find_transcript(['en']):
            transcript = transcripts.find_transcript(['en']).fetch()
            transcript_text = "\n".join([f"[{format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript])
            print(f"[get_youtube_transcript] ì˜ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
            return transcript_text
    except (TranscriptsDisabled, NoTranscriptFound):
        print("[get_youtube_transcript] ì˜ì–´ ìë§‰ ì—†ìŒ.")
        pass
    except Exception as e:
        raise ValueError(f"ë¹„ë””ì˜¤ {video_id}ì˜ ìë§‰ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

    try:
        # ê¸°íƒ€ ì–¸ì–´ ìë§‰ ì‹œë„
        transcript = transcripts.find_transcript(transcripts._languages).fetch()
        transcript_text = "\n".join([f"[{format_timestamp(entry['start'])}] {entry['text']}" for entry in transcript])
        print(f"[get_youtube_transcript] ê¸°íƒ€ ì–¸ì–´ ìë§‰ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(transcript_text)}")
        return transcript_text
    except Exception as e:
        raise ValueError(f"ë¹„ë””ì˜¤ {video_id}ì˜ ìë§‰ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")


# -------------------
# 6-1. get_youtube_transcript -> format_timestamp
# -------------------
def format_timestamp(seconds):
    """ì´ˆë¥¼ HH:MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    return f"{hours:02d}:{minutes:02d}:{secs:02d}"


# -------------------
# 7. process_link -> get_text_from_file
# -------------------
def get_text_from_file(url):
    """í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš© ì½ê¸°"""
    try:
        response = requests.get(url)
        response.raise_for_status()
        text = response.text.strip()
        print(f"[get_text_from_file] í…ìŠ¤íŠ¸ íŒŒì¼ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(text)}")
        return text
    except Exception as e:
        raise ValueError(f"í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# -------------------
# 8. process_link -> get_text_from_webpage
# -------------------
def get_text_from_webpage(url):
    """ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, "html.parser")
        text = soup.get_text(separator="\n").strip()
        # ê¸¸ì´ ì œí•œ 10000ì
        text = text[:10000]
        print(f"[get_text_from_webpage] ì›¹í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ê¸¸ì´: {len(text)}")
        return text
    except Exception as e:
        raise ValueError(f"ì›¹í˜ì´ì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# -------------------
# 9. process_urls -> split_text
# -------------------
def split_text(text, max_chunk_size=CHUNK_SIZE):
    """
    í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€ í¬ê¸°ì— ë§ê²Œ ë¶„í• í•©ë‹ˆë‹¤.
    ëŒ€ëµì ì¸ ë‹¨ì–´ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• .
    """
    words = text.split()
    total_words = len(words)
    num_chunks = ceil(total_words / (max_chunk_size // 5))
    chunks = []
    for i in range(num_chunks):
        start = i * (max_chunk_size // 5)
        end = start + (max_chunk_size // 5)
        chunk = ' '.join(words[start:end])
        chunks.append(chunk)
    print(f"[split_text] ì´ ë‹¨ì–´ ìˆ˜: {total_words}, ì²­í¬ ìˆ˜: {num_chunks}")
    return chunks


# -------------------
# 10. process_urls -> save_chunks
# -------------------
def save_chunks(chunks, directory="chunks"):
    """í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    if not os.path.exists(directory):
        os.makedirs(directory)
        print(f"[save_chunks] '{directory}' ë””ë ‰í† ë¦¬ ìƒì„±.")
    
    for idx, chunk in enumerate(chunks, 1):
        file_path = os.path.join(directory, f"chunk_{idx}.txt")
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(chunk)
        print(f"[save_chunks] ì²­í¬ {idx} ì €ì¥: {file_path}")
    print(f"[save_chunks] {len(chunks)}ê°œì˜ ì²­í¬ê°€ '{directory}' ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


# -------------------
# 11. process_urls -> summarize_text
# -------------------
def summarize_text(transcript_chunks, model=MODEL):
    """
    ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ChatGPTë¡œ ì„¸ë¶„í™”ëœ ìš”ì•½ ì‘ì—… ìˆ˜í–‰.
    ê° ì²­í¬ë³„ë¡œ ìš”ì•½ì„ ë°›ê³ , ìµœì¢…ì ìœ¼ë¡œ í†µí•© ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    summaries = []
    # (1) ê° ì²­í¬ë¥¼ ìˆœíšŒí•˜ë©° ìš”ì•½
    for idx, chunk in enumerate(transcript_chunks):
        prompt = generate_prompt(chunk)
        try:
            response = openai.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are a travel expert who provides detailed recommendations for places to visit, foods to eat, precautions, and suggestions based on transcripts."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=1500
            )
            summary = response.choices[0].message.content
            summaries.append(summary)
            print(f"ì²­í¬ {idx+1}/{len(transcript_chunks)} ìš”ì•½ ì™„ë£Œ.")
            print(f"[ì²­í¬ {idx+1} ìš”ì•½ ë‚´ìš© ì¼ë¶€]")
            print(summary[:500])  # ì²« 500ì ì¶œë ¥
        except Exception as e:
            raise ValueError(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # (2) ê°œë³„ ìš”ì•½ì„ í•©ì³ì„œ ìµœì¢… ìš”ì•½
    combined_summaries = "\n".join(summaries)
    final_prompt = f"""
ì•„ë˜ëŠ” ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ë‰œ ìš”ì•½ì…ë‹ˆë‹¤. ì´ ìš”ì•½ë“¤ì„ í†µí•©í•˜ì—¬ ë‹¤ìŒì˜ í˜•ì‹ìœ¼ë¡œ ìµœì¢… ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ê³ , ë¹ ì§€ëŠ” ë‚´ìš© ì—†ì´ ëª¨ë“  ì •ë³´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
**ìš”êµ¬ ì‚¬í•­:**
1. ì¥ì†Œ, ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ ë“± ê°ê°ì˜ ì •ë³´ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
2. ë§Œì•½ í•´ë‹¹ ì¥ì†Œì—ì„œ ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì´ ì—†ë‹¤ë©´ ì‘ì„±í•˜ì§€ ì•Šê³  ë„˜ì–´ê°€ë„ ë©ë‹ˆë‹¤.
3. ë°©ë¬¸í•œ ì¥ì†Œê°€ ì—†ê±°ë‚˜ ìœ ì˜ ì‚¬í•­ë§Œ ìˆì„ ë•Œ, ìœ ì˜ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
4. ì¶”ì²œ ì‚¬í•­ë§Œ ìˆëŠ” ê²ƒë“¤ì€ ì¶”ì²œ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
5. ê°€ëŠ¥í•œ ì¥ì†Œ ì´ë¦„ì„ ì•Œê³  ìˆë‹¤ë©´ ì‹¤ì œ ì£¼ì†Œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”
ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 

ë°©ë¬¸í•œ ì¥ì†Œ: ìŠ¤ë¯¸ë‹¤ íƒ€ì›Œ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ë„ì¿„ ìŠ¤ì¹´ì´íŠ¸ë¦¬ë¥¼ ëŒ€í‘œí•˜ëŠ” ëœë“œë§ˆí¬ë¡œ, ì „ë§ëŒ€ì—ì„œ ë„ì¿„ ì‹œë‚´ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” ë‚ ì”¨ê°€ ì¢‹ì•„ì„œ í›„ì§€ì‚°ê¹Œì§€ ë³´ì˜€ê³ , ì•¼ê²½ì´ íŠ¹íˆ ì•„ë¦„ë‹¤ì› ë‹¤ê³  í•©ë‹ˆë‹¤.
- ë¨¹ì€ ìŒì‹: ë¼ë©˜ ì´ì¹˜ë€
    - ì„¤ëª…: ì§„í•œ êµ­ë¬¼ê³¼ ì«„ê¹ƒí•œ ë©´ë°œë¡œ ìœ ëª…í•œ ë¼ë©˜ ì²´ì¸ì ìœ¼ë¡œ, ê°œì¸ì‹¤ì—ì„œ í¸ì•ˆí•˜ê²Œ ì‹ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: í˜¼ì¡í•œ ì‹œê°„ëŒ€ í”¼í•˜ê¸°
    - ì„¤ëª…: ê´€ê´‘ì§€ ì£¼ë³€ì€ íŠ¹íˆ ì£¼ë§ê³¼ íœ´ì¼ì— ë§¤ìš° í˜¼ì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°€ëŠ¥í•œ í‰ì¼ì´ë‚˜ ì´ë¥¸ ì‹œê°„ì— ë°©ë¬¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì¶”ì²œ ì‚¬í•­: ìŠ¤ì¹´ì´ íŠ¸ë¦¬ ì „ë§ëŒ€ ë°©ë¬¸
    - ì„¤ëª…: ë„ì¿„ì˜ ì•„ë¦„ë‹¤ìš´ ì•¼ê²½ì„ ê°ìƒí•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ì§„ ì´¬ì˜ í•˜ê¸°ì— ìµœì ì˜ ì¥ì†Œì…ë‹ˆë‹¤.

ë°©ë¬¸í•œ ì¥ì†Œ: ìœ ë‹ˆë²„ì…œ ìŠ¤íŠœë””ì˜¤ ì¼ë³¸ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” í‰ì¼ì„ì—ë„ ì‚¬ëŒì´ ë§ì•˜ì§€ë§Œ, ì‹±ê¸€ë¼ì´ë”ë¥¼ ì´ìš©í•´ì„œ ëŒ€ê¸° ì‹œê°„ì„ ë§ì´ ì¤„ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•´ë¦¬í¬í„° êµ¬ì—­ì˜ ë¶„ìœ„ê¸°ê°€ ì‹¤ì œ ì˜í™”ì˜ í•œ ì¥ë©´ì— ë“¤ì–´ì˜¨ ê²ƒ ê°™ì•˜ê³ , ë²„í„°ë§¥ì£¼ë„ ë§›ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: ì§§ì€ ì˜· ì°©ìš© 
    - ì„¤ëª…: íŒ€ë© í”Œë˜ë‹›ì˜ ì¼ë¶€ êµ¬ì—­ì—ì„œëŠ” ë¬¼ì´ ë†’ê³  ê±°ìš¸ì´ ìˆìœ¼ë¯€ë¡œ, ì§§ì€ ì˜·ì„ ì…ëŠ” ê²ƒì´ ì¢‹ë‹¤.

**ìš”ì•½ ì²­í¬:**
{combined_summaries}

**ìµœì¢… ìš”ì•½:**
"""
    try:
        final_response = openai.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are an expert summary writer who strictly adheres to the provided format."},
                {"role": "user", "content": final_prompt}
            ],
            temperature=0.1,
            max_tokens=4096
        )
        final_summary = final_response.choices[0].message.content
        print("\n[ìµœì¢… ìš”ì•½ ë‚´ìš© ì¼ë¶€]")
        print(final_summary[:1000])  # ì²« 1000ì ì¶œë ¥
        return final_summary
    except Exception as e:
        raise ValueError(f"ìµœì¢… ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# -------------------
# 11-1. summarize_text -> generate_prompt
# -------------------
def generate_prompt(transcript_chunk):
    """
    ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ OpenAI APIì— ì „ë‹¬.
    í•œêµ­ì–´ê°€ ì•„ë‹ˆë©´ ë²ˆì—­ ì•ˆë‚´ë¥¼ ì¶”ê°€.
    """
    language = detect(transcript_chunk)
    if language != 'ko':
        translation_instruction = "ì´ í…ìŠ¤íŠ¸ëŠ” í•œêµ­ì–´ê°€ ì•„ë‹™ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ ì£¼ì„¸ìš”.\n\n"
    else:
        translation_instruction = ""

    base_prompt = f"""
{translation_instruction}
ì•„ë˜ëŠ” ì—¬í–‰ ìœ íŠœë²„ê°€ ì´¬ì˜í•œ ì˜ìƒì˜ ìë§‰ì…ë‹ˆë‹¤. ì´ ìë§‰ì—ì„œ ë°©ë¬¸í•œ ì¥ì†Œ, ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

**ìš”êµ¬ ì‚¬í•­:**
1. ì¥ì†Œ, ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ ë“± ê°ê°ì˜ ì •ë³´ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
2. ë§Œì•½ í•´ë‹¹ ì¥ì†Œì—ì„œ ë¨¹ì€ ìŒì‹, ìœ ì˜ ì‚¬í•­, ì¶”ì²œ ì‚¬í•­ì´ ì—†ë‹¤ë©´ ì‘ì„±í•˜ì§€ ì•Šê³  ë„˜ì–´ê°€ë„ ë©ë‹ˆë‹¤.
3. ë°©ë¬¸í•œ ì¥ì†Œê°€ ì—†ê±°ë‚˜ ìœ ì˜ ì‚¬í•­ë§Œ ìˆì„ ë•Œ, ìœ ì˜ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
4. ì¶”ì²œ ì‚¬í•­ë§Œ ìˆëŠ” ê²ƒë“¤ì€ ì¶”ì²œ ì‚¬í•­ ì„¹ì…˜ì— ëª¨ì•„ì£¼ì„¸ìš”.
5. ê°€ëŠ¥í•œ ì¥ì†Œ ì´ë¦„ì„ ì•Œê³  ìˆë‹¤ë©´ ì‹¤ì œ ì£¼ì†Œë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.
6. ì¥ì†Œ ì„¤ëª…ì€ ë°˜ë“œì‹œ ìœ íŠœë²„ê°€ ì–¸ê¸‰í•œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. ìœ íŠœë²„ì˜ ì‹¤ì œ ê²½í—˜ê³¼ í‰ê°€ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.

**ê²°ê³¼ í˜•ì‹:**

ê²°ê³¼ëŠ” ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”
ì•„ë˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 

ë°©ë¬¸í•œ ì¥ì†Œ: ìŠ¤ë¯¸ë‹¤ íƒ€ì›Œ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ë„ì¿„ ìŠ¤ì¹´ì´íŠ¸ë¦¬ë¥¼ ëŒ€í‘œí•˜ëŠ” ëœë“œë§ˆí¬ë¡œ, ì „ë§ëŒ€ì—ì„œ ë„ì¿„ ì‹œë‚´ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” ë‚ ì”¨ê°€ ì¢‹ì•„ì„œ í›„ì§€ì‚°ê¹Œì§€ ë³´ì˜€ê³ , ì•¼ê²½ì´ íŠ¹íˆ ì•„ë¦„ë‹¤ì› ë‹¤ê³  í•©ë‹ˆë‹¤.
- ë¨¹ì€ ìŒì‹: ë¼ë©˜ ì´ì¹˜ë€
    - ì„¤ëª…: ì§„í•œ êµ­ë¬¼ê³¼ ì«„ê¹ƒí•œ ë©´ë°œë¡œ ìœ ëª…í•œ ë¼ë©˜ ì²´ì¸ì ìœ¼ë¡œ, ê°œì¸ì‹¤ì—ì„œ í¸ì•ˆí•˜ê²Œ ì‹ì‚¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: í˜¼ì¡í•œ ì‹œê°„ëŒ€ í”¼í•˜ê¸°
    - ì„¤ëª…: ê´€ê´‘ì§€ ì£¼ë³€ì€ íŠ¹íˆ ì£¼ë§ê³¼ íœ´ì¼ì— ë§¤ìš° í˜¼ì¡í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ê°€ëŠ¥í•œ í‰ì¼ì´ë‚˜ ì´ë¥¸ ì‹œê°„ì— ë°©ë¬¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
- ì¶”ì²œ ì‚¬í•­: ìŠ¤ì¹´ì´ íŠ¸ë¦¬ ì „ë§ëŒ€ ë°©ë¬¸
    - ì„¤ëª…: ë„ì¿„ì˜ ì•„ë¦„ë‹¤ìš´ ì•¼ê²½ì„ ê°ìƒí•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ì§„ ì´¬ì˜ í•˜ê¸°ì— ìµœì ì˜ ì¥ì†Œì…ë‹ˆë‹¤.

ë°©ë¬¸í•œ ì¥ì†Œ: ìœ ë‹ˆë²„ì…œ ìŠ¤íŠœë””ì˜¤ ì¼ë³¸ (ì£¼ì†Œ) íƒ€ì„ìŠ¤íƒ¬í”„: [HH:MM:SS]
- ì¥ì†Œì„¤ëª…: [ìœ íŠœë²„ì˜ ì„¤ëª…] ìœ íŠœë²„ê°€ ë°©ë¬¸í–ˆì„ ë•ŒëŠ” í‰ì¼ì„ì—ë„ ì‚¬ëŒì´ ë§ì•˜ì§€ë§Œ, ì‹±ê¸€ë¼ì´ë”ë¥¼ ì´ìš©í•´ì„œ ëŒ€ê¸° ì‹œê°„ì„ ë§ì´ ì¤„ì¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í•´ë¦¬í¬í„° êµ¬ì—­ì˜ ë¶„ìœ„ê¸°ê°€ ì‹¤ì œ ì˜í™”ì˜ í•œ ì¥ë©´ì— ë“¤ì–´ì˜¨ ê²ƒ ê°™ì•˜ê³ , ë²„í„°ë§¥ì£¼ë„ ë§›ìˆì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.
- ìœ ì˜ ì‚¬í•­: ì§§ì€ ì˜· ì°©ìš© 
    - ì„¤ëª…: íŒ€ë© í”Œë˜ë‹›ì˜ ì¼ë¶€ êµ¬ì—­ì—ì„œëŠ” ë¬¼ì´ ë†’ê³  ê±°ìš¸ì´ ìˆìœ¼ë¯€ë¡œ, ì§§ì€ ì˜·ì„ ì…ëŠ” ê²ƒì´ ì¢‹ë‹¤.

**ìë§‰:**
{transcript_chunk}

ìœ„ ìë§‰ì„ ë°”íƒ•ìœ¼ë¡œ ìœ„ì˜ ìš”êµ¬ ì‚¬í•­ì— ë§ëŠ” ì •ë³´ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”. íŠ¹íˆ ì¥ì†Œ ì„¤ëª…ì€ ë°˜ë“œì‹œ ìœ íŠœë²„ê°€ ì‹¤ì œë¡œ ì–¸ê¸‰í•œ ë‚´ìš©ê³¼ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""
    print("\n[generate_prompt] ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì¼ë¶€:")
    print(base_prompt[:500])  # ì²« 500ì ì¶œë ¥
    return base_prompt


# -------------------
# 12. process_urls -> extract_place_names
# -------------------
def extract_place_names(summary):
    """ìš”ì•½ì—ì„œ 'ë°©ë¬¸í•œ ì¥ì†Œ:' ë¼ì¸ì„ ì°¾ì•„ ì¥ì†Œ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    place_names = []
    lines = summary.split("\n")
    
    for line in lines:
        if line.startswith("ë°©ë¬¸í•œ ì¥ì†Œ:"):
            try:
                place_info = line.replace("ë°©ë¬¸í•œ ì¥ì†Œ:", "").strip()
                place_name = place_info.split("(")[0].strip()
                if place_name and place_name not in place_names:
                    place_names.append(place_name)
            except Exception as e:
                print(f"ì¥ì†Œ ì´ë¦„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
    return place_names


# -------------------
# 13. process_urls -> search_place_details
# -------------------
def search_place_details(place_name: str) -> Dict[str, Any]:
    """Google Places APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ ìƒì„¸ ì •ë³´ ê²€ìƒ‰"""
    try:
        # Places API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        gmaps = googlemaps.Client(key=os.getenv("GOOGLE_PLACES_API_KEY"))
        
        # ì¥ì†Œ ê²€ìƒ‰
        places_result = gmaps.places(place_name)
        
        if places_result['results']:
            place = places_result['results'][0]
            
            # ìƒì„¸ ì •ë³´ êµ¬ì„±
            details = {
                'name': place.get('name', ''),
                'formatted_address': place.get('formatted_address', ''),
                'rating': place.get('rating'),
                'phone': place.get('formatted_phone_number', ''),
                'website': place.get('website', ''),
                'price_level': place.get('price_level'),
                'opening_hours': place.get('opening_hours', {}).get('weekday_text', []),
                'photos': []
            }
            
            return details
            
    except Exception as e:
        print(f"ì¥ì†Œ ì •ë³´ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# -------------------
# 14. process_urls -> get_place_photo_google
# -------------------
def get_place_photo_google(place_name, api_key):
    """
    Google Places APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì¥ì†Œ IDë¥¼ ê²€ìƒ‰í•œ ë’¤,
    place_idë¡œ ì‚¬ì§„ì˜ photoreferenceë¥¼ ì–»ê³ 
    ìµœì¢…ì ìœ¼ë¡œ ì‚¬ì§„ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        search_url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
        search_params = {
            "input": place_name,
            "inputtype": "textquery",
            "fields": "photos,place_id",
            "key": api_key
        }
        search_response = requests.get(search_url, params=search_params)
        if search_response.status_code == 200:
            search_data = search_response.json()
            if search_data.get('candidates'):
                place_id = search_data['candidates'][0]['place_id']
                details_url = "https://maps.googleapis.com/maps/api/place/details/json"
                details_params = {
                    "place_id": place_id,
                    "fields": "photos",
                    "key": api_key
                }
                details_response = requests.get(details_url, params=details_params)
                if details_response.status_code == 200:
                    details_data = details_response.json()
                    if 'result' in details_data and 'photos' in details_data['result']:
                        photo_reference = details_data['result']['photos'][0]['photo_reference']
                        photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_reference}&key={api_key}"
                        print(f"[get_place_photo_google] ì‚¬ì§„ URL ìƒì„± ì™„ë£Œ: {photo_url}")  # ë””ë²„ê¹… ì¶œë ¥
                        return photo_url
            print(f"[get_place_photo_google] ì‚¬ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {place_name}")
            return "ì‚¬ì§„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            print(f"[get_place_photo_google] API ìš”ì²­ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {search_response.status_code}")
            return "API ìš”ì²­ ì‹¤íŒ¨."
    except Exception as e:
        print(f"[get_place_photo_google] ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "API ìš”ì²­ ì‹¤íŒ¨."


# -------------------
# 15. process_urls -> save_final_summary
# -------------------
def save_final_summary(final_summary, file_path="final_summary.txt"):
    """ìµœì¢… ìš”ì•½ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    file_path = f"final_summary_{timestamp}.txt"
    try:
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(final_summary)
        print(f"ìµœì¢… ìš”ì•½ì´ '{file_path}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("\n[save_final_summary] ìµœì¢… ìš”ì•½ ë‚´ìš© ì¼ë¶€:")
        print(final_summary[:1000])  # ì²« 1000ì ì¶œë ¥
    except Exception as e:
        print(f"ìµœì¢… ìš”ì•½ì„ ì €ì¥í•˜ëŠ”ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# -------------------
# (ê¸°íƒ€) ì‚¬ìš©ë˜ì§€ ì•Šì•˜ìœ¼ë‚˜ ì›ë³¸ ì½”ë“œì— í¬í•¨ëœ í•¨ìˆ˜ë“¤
# -------------------
def count_tokens(text, model=MODEL):
    """
    í…ìŠ¤íŠ¸ê°€ ëª‡ ê°œì˜ í† í°ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆëŠ”ì§€ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜.
    ì›ë³¸ ì½”ë“œì— í¬í•¨ë˜ì–´ ìˆìœ¼ë‚˜ ì‹¤ì œë¡œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))


def get_address_google(place_name, api_key):
    """
    Google Geocoding APIë¥¼ í†µí•´ ì£¼ì†Œë¥¼ ì°¾ëŠ” í•¨ìˆ˜.
    ì›ë³¸ ì½”ë“œì— í¬í•¨ë˜ì–´ ìˆìœ¼ë‚˜ ì‹¤ì œë¡œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    try:
        base_url = "https://maps.googleapis.com/maps/api/geocode/json"
        params = {
            "address": place_name,
            "key": api_key
        }
        response = requests.get(base_url, params=params)
        if response.status_code == 200:
            data = response.json()
            if data['results']:
                address = data['results'][0]['formatted_address']
                print(f"[get_address_google] ì£¼ì†Œ ì°¾ìŒ: {address}")  # ë””ë²„ê¹… ì¶œë ¥
                return address
            else:
                print(f"[get_address_google] ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {place_name}")
                return "ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        else:
            print(f"[get_address_google] API ìš”ì²­ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {response.status_code}")
            return "API ìš”ì²­ ì‹¤íŒ¨."
    except Exception as e:
        print(f"[get_address_google] ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "API ìš”ì²­ ì‹¤íŒ¨."


# ë©”ì¸ ì‹¤í–‰ ì½”ë“œë¥¼ í•¨ìˆ˜ ì •ì˜ ë’¤ë¡œ ì´ë™
if __name__ == "__main__":
    print("ìµœëŒ€ 5ê°œì˜ URLì„ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì…ë ¥ì„ ë§ˆì¹˜ë ¤ë©´ ë¹ˆ ì¤„ì„ ì…ë ¥í•˜ì„¸ìš”.")
    input_urls = []
    for i in range(MAX_URLS):
        url = input(f"URL {i+1}: ").strip()
        if not url:
            break
        input_urls.append(url)
    
    if not input_urls:
        print("ì…ë ¥ëœ URLì´ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        try:
            summary = process_urls(input_urls)
            print("\n[ìµœì¢… ìš”ì•½]")
            print(summary)
        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")
